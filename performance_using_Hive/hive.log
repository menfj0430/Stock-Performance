2015-03-31 23:13:08,353 WARN  [main]: common.LogUtils (LogUtils.java:logConfigLocation(140)) - DEPRECATED: Ignoring hive-default.xml found on the CLASSPATH at /gpfs/courses/cse587/spring2015/students/u2/hw3/hive_official/src/config-3611349/hive-default.xml
2015-03-31 23:13:08,356 WARN  [main]: common.LogUtils (LogUtils.java:logConfigLocation(145)) - hive-site.xml not found on CLASSPATH
2015-03-31 23:13:08,473 INFO  [main]: SessionState (SessionState.java:printInfo(824)) - 
Logging initialized using configuration in file:/gpfs/courses/cse587/spring2015/students/u2/hw3/hive_official/src/config-3611349/hive-log4j.properties
2015-03-31 23:13:08,768 WARN  [main]: util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(62)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-31 23:13:08,824 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:newRawStore(556)) - 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
2015-03-31 23:13:08,847 INFO  [main]: metastore.ObjectStore (ObjectStore.java:initialize(264)) - ObjectStore, initialize called
2015-03-31 23:13:16,486 INFO  [main]: metastore.ObjectStore (ObjectStore.java:getPMF(345)) - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2015-03-31 23:13:16,540 INFO  [main]: metastore.MetaStoreDirectSql (MetaStoreDirectSql.java:<init>(109)) - MySQL check failed, assuming we are not on mysql: Lexical error at line 1, column 5.  Encountered: "@" (64), after : "".
2015-03-31 23:13:25,090 INFO  [main]: metastore.ObjectStore (ObjectStore.java:setConf(247)) - Initialized ObjectStore
2015-03-31 23:13:25,383 WARN  [main]: metastore.ObjectStore (ObjectStore.java:checkSchema(6570)) - Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 0.14.0
2015-03-31 23:13:25,930 WARN  [main]: metastore.ObjectStore (ObjectStore.java:getDatabase(538)) - Failed to get database default, returning NoSuchObjectException
2015-03-31 23:13:26,672 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:createDefaultRoles_core(630)) - Added admin role in metastore
2015-03-31 23:13:26,675 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:createDefaultRoles_core(639)) - Added public role in metastore
2015-03-31 23:13:26,957 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:addAdminUsers_core(679)) - No user is added in admin role, since config is empty
2015-03-31 23:13:27,168 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created HDFS directory: /tmp/hive/u2
2015-03-31 23:13:27,180 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created local directory: /tmp/c7e988b4-54b2-4b89-b7f4-52d3f8935901_resources
2015-03-31 23:13:27,183 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created HDFS directory: /tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901
2015-03-31 23:13:27,204 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created local directory: /tmp/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901
2015-03-31 23:13:27,206 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created HDFS directory: /tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/_tmp_space.db
2015-03-31 23:13:27,208 INFO  [main]: session.SessionState (SessionState.java:start(460)) - No Tez session required at this point. hive.execution.engine=mr.
2015-03-31 23:13:27,273 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,273 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,273 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:13:27,273 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,301 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,304 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: DROP table stock_prices
2015-03-31 23:13:27,492 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:13:27,494 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427858007301 end=1427858007494 duration=193 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,496 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,523 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=stock_prices
2015-03-31 23:13:27,524 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=stock_prices	
2015-03-31 23:13:27,559 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:13:27,559 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427858007496 end=1427858007559 duration=63 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,566 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:13:27,566 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427858007273 end=1427858007566 duration=293 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,566 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,567 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: DROP table stock_prices
2015-03-31 23:13:27,570 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427858007273 end=1427858007570 duration=297 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,570 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,570 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,574 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:13:27,575 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=stock_prices
2015-03-31 23:13:27,575 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=stock_prices	
2015-03-31 23:13:27,576 ERROR [main]: metadata.Hive (Hive.java:getTable(1063)) - Table stock_prices not found: default.stock_prices table not found
2015-03-31 23:13:27,583 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=stock_prices
2015-03-31 23:13:27,583 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=stock_prices	
2015-03-31 23:13:27,584 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427858007570 end=1427858007584 duration=14 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,584 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427858007566 end=1427858007584 duration=18 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,585 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:13:27,585 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,585 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427858007585 end=1427858007585 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,585 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427858007273 end=1427858007585 duration=312 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,586 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.316 seconds
2015-03-31 23:13:27,587 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,587 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,587 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:13:27,587 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,588 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,588 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command:  CREATE EXTERNAL TABLE stock_prices (stock_date STRING, Open FLOAT, High FLOAT, Low FLOAT, Close FLOAT, Volume FLOAT, Adj_Close FLOAT)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n'
STORED AS TEXTFILE
LOCATION '/user/'
tblproperties ("skip.header.line.count"="1")
2015-03-31 23:13:27,595 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:13:27,596 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427858007588 end=1427858007596 duration=8 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,596 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,618 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:13:27,629 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeCreateTable(10828)) - Creating table default.stock_prices position=23
2015-03-31 23:13:27,644 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:13:27,644 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:13:27,689 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:13:27,689 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427858007596 end=1427858007689 duration=93 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,690 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:13:27,690 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427858007587 end=1427858007690 duration=103 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,690 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,690 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command:  CREATE EXTERNAL TABLE stock_prices (stock_date STRING, Open FLOAT, High FLOAT, Low FLOAT, Close FLOAT, Volume FLOAT, Adj_Close FLOAT)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n'
STORED AS TEXTFILE
LOCATION '/user/'
tblproperties ("skip.header.line.count"="1")
2015-03-31 23:13:27,691 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427858007587 end=1427858007691 duration=104 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,691 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,691 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,692 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:13:27,749 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: create_table: Table(tableName:stock_prices, dbName:default, owner:u2, createTime:1427858007, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:open, type:float, comment:null), FieldSchema(name:high, type:float, comment:null), FieldSchema(name:low, type:float, comment:null), FieldSchema(name:close, type:float, comment:null), FieldSchema(name:volume, type:float, comment:null), FieldSchema(name:adj_close, type:float, comment:null)], location:/user, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{line.delim=
, serialization.format=,, field.delim=,}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{EXTERNAL=TRUE, skip.header.line.count=1}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2015-03-31 23:13:27,750 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=create_table: Table(tableName:stock_prices, dbName:default, owner:u2, createTime:1427858007, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:open, type:float, comment:null), FieldSchema(name:high, type:float, comment:null), FieldSchema(name:low, type:float, comment:null), FieldSchema(name:close, type:float, comment:null), FieldSchema(name:volume, type:float, comment:null), FieldSchema(name:adj_close, type:float, comment:null)], location:/user, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{line.delim=
, serialization.format=,, field.delim=,}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{EXTERNAL=TRUE, skip.header.line.count=1}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2015-03-31 23:13:27,758 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for stock_prices
2015-03-31 23:13:27,758 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table stock_prices to 0
2015-03-31 23:13:27,851 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427858007691 end=1427858007851 duration=160 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,851 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427858007690 end=1427858007851 duration=161 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,851 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:13:27,851 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,851 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427858007851 end=1427858007851 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,851 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427858007587 end=1427858007851 duration=264 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,852 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.264 seconds
2015-03-31 23:13:27,852 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,852 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,852 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:13:27,852 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,853 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,853 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 


drop table reqddata
2015-03-31 23:13:27,853 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:13:27,854 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427858007853 end=1427858007854 duration=1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,854 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,854 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:13:27,855 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:13:27,856 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:13:27,856 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427858007854 end=1427858007856 duration=2 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,856 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:13:27,856 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427858007852 end=1427858007856 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,856 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,856 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 


drop table reqddata
2015-03-31 23:13:27,856 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427858007852 end=1427858007856 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,856 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,857 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,857 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:13:27,857 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:13:27,858 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:13:27,859 ERROR [main]: metadata.Hive (Hive.java:getTable(1063)) - Table reqddata not found: default.reqddata table not found
2015-03-31 23:13:27,859 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:13:27,859 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:13:27,860 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427858007856 end=1427858007860 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,860 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427858007856 end=1427858007860 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,860 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:13:27,861 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,861 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427858007861 end=1427858007861 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,861 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427858007852 end=1427858007861 duration=9 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,861 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.0090 seconds
2015-03-31 23:13:27,861 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,861 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,861 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:13:27,861 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,862 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,862 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: create table reqddata(stock_name STRING, stock_date STRING, month STRING, Adj_Close FLOAT)
2015-03-31 23:13:27,863 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:13:27,863 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427858007862 end=1427858007863 duration=1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,863 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,863 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:13:27,864 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeCreateTable(10828)) - Creating table default.reqddata position=13
2015-03-31 23:13:27,864 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:13:27,864 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:13:27,865 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:13:27,866 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427858007863 end=1427858007865 duration=2 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,866 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:13:27,866 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427858007861 end=1427858007866 duration=5 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,866 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,866 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: create table reqddata(stock_name STRING, stock_date STRING, month STRING, Adj_Close FLOAT)
2015-03-31 23:13:27,866 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427858007861 end=1427858007866 duration=5 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,866 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,866 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,867 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:13:27,869 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: create_table: Table(tableName:reqddata, dbName:default, owner:u2, createTime:1427858007, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:month, type:string, comment:null), FieldSchema(name:adj_close, type:float, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2015-03-31 23:13:27,869 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=create_table: Table(tableName:reqddata, dbName:default, owner:u2, createTime:1427858007, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:month, type:string, comment:null), FieldSchema(name:adj_close, type:float, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2015-03-31 23:13:27,873 INFO  [main]: common.FileUtils (FileUtils.java:mkdir(504)) - Creating directory if it doesn't exist: hdfs://k05n26:54310/user/hive/warehouse/reqddata
2015-03-31 23:13:27,891 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427858007866 end=1427858007891 duration=25 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,891 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427858007866 end=1427858007891 duration=25 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,891 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:13:27,892 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,892 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427858007892 end=1427858007892 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,892 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427858007861 end=1427858007892 duration=31 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,892 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.031 seconds
2015-03-31 23:13:27,892 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,892 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,892 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:13:27,893 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,893 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,893 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 
insert overwrite table reqddata select regexp_replace( regexp_replace(INPUT__FILE__NAME,'.*/',''),'\\..*','') as stock_name, stock_date, substr(stock_date,0,7) as month, Adj_Close from stock_prices
2015-03-31 23:13:27,909 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:13:27,909 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427858007893 end=1427858007909 duration=16 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,910 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:27,910 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:13:28,244 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10000)) - Completed phase 1 of Semantic Analysis
2015-03-31 23:13:28,244 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1554)) - Get metadata for source tables
2015-03-31 23:13:28,245 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=stock_prices
2015-03-31 23:13:28,245 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=stock_prices	
2015-03-31 23:13:28,376 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1702)) - Get metadata for subqueries
2015-03-31 23:13:28,376 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1726)) - Get metadata for destination tables
2015-03-31 23:13:28,378 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:13:28,378 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:13:28,391 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10003)) - Completed getting MetaData in Semantic Analysis
2015-03-31 23:13:28,465 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:genFileSinkPlan(6412)) - Set stats collection dir : hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1/-ext-10001
2015-03-31 23:13:28,525 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for FS(2)
2015-03-31 23:13:28,526 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(1)
2015-03-31 23:13:28,526 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(0)
2015-03-31 23:13:28,576 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:13:28,579 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427858008576 end=1427858008579 duration=3 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:13:28,581 INFO  [main]: optimizer.GenMRFileSink1 (GenMRFileSink1.java:process(103)) - using CombineHiveInputformat for the merge job
2015-03-31 23:13:28,597 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:13:28,597 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:13:28,598 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:13:28,598 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:13:28,599 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:13:28,600 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:13:28,601 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10173)) - Completed plan generation
2015-03-31 23:13:28,601 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:13:28,601 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427858007910 end=1427858008601 duration=691 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:28,602 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:month, type:string, comment:null), FieldSchema(name:adj_close, type:float, comment:null)], properties:null)
2015-03-31 23:13:28,602 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427858007893 end=1427858008602 duration=709 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:28,602 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:28,602 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 
insert overwrite table reqddata select regexp_replace( regexp_replace(INPUT__FILE__NAME,'.*/',''),'\\..*','') as stock_name, stock_date, substr(stock_date,0,7) as month, Adj_Close from stock_prices
2015-03-31 23:13:28,602 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Query ID = u2_20150331231313_3d76e571-56b0-4c18-bb29-293c832f190f
2015-03-31 23:13:28,602 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total jobs = 3
2015-03-31 23:13:28,603 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427858007892 end=1427858008603 duration=711 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:28,603 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:28,603 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPRED.Stage-1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:28,616 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Launching Job 1 out of 3
2015-03-31 23:13:28,618 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-1:MAPRED] in serial mode
2015-03-31 23:13:28,618 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Number of reduce tasks is set to 0 since there's no reduce operator
2015-03-31 23:13:28,619 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1
2015-03-31 23:13:28,626 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(287)) - Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2015-03-31 23:13:28,630 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3265)) - Processing alias stock_prices
2015-03-31 23:13:28,630 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3282)) - Adding input file hdfs://k05n26:54310/user
2015-03-31 23:13:28,630 INFO  [main]: exec.Utilities (Utilities.java:isEmptyPath(2605)) - Content Summary not cached for hdfs://k05n26:54310/user
2015-03-31 23:13:28,633 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1
2015-03-31 23:13:28,651 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:13:28,652 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapWork via kryo
2015-03-31 23:13:28,843 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427858008651 end=1427858008843 duration=192 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:13:28,845 INFO  [main]: Configuration.deprecation (Configuration.java:warnOnceIfDeprecated(1019)) - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication
2015-03-31 23:13:28,926 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n26/10.111.5.26:8032
2015-03-31 23:13:29,037 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1/-ext-10001
2015-03-31 23:13:29,061 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n26/10.111.5.26:8032
2015-03-31 23:13:29,066 INFO  [main]: exec.Utilities (Utilities.java:getBaseWork(419)) - No plan file found: hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1/-mr-10004/f16a726a-c227-42ea-81b9-070c48104211/reduce.xml
2015-03-31 23:13:29,340 WARN  [main]: mapreduce.JobSubmitter (JobSubmitter.java:copyAndConfigureFiles(150)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-03-31 23:13:29,489 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:13:29,501 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(387)) - CombineHiveInputSplit creating pool for hdfs://k05n26:54310/user; using filter path hdfs://k05n26:54310/user
2015-03-31 23:13:29,509 INFO  [main]: input.FileInputFormat (FileInputFormat.java:listStatus(281)) - Total input paths to process : 1
2015-03-31 23:13:29,512 INFO  [main]: input.CombineFileInputFormat (CombineFileInputFormat.java:createSplits(413)) - DEBUG: Terminated node allocation with : CompletedNodes: 0, size left: 0
2015-03-31 23:13:29,514 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(442)) - number of splits 0
2015-03-31 23:13:29,514 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getSplits start=1427858009489 end=1427858009514 duration=25 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:13:29,515 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(521)) - Number of all splits 0
2015-03-31 23:13:29,539 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(396)) - number of splits:0
2015-03-31 23:13:29,622 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:printTokens(479)) - Submitting tokens for job: job_1427857797694_0001
2015-03-31 23:13:29,869 INFO  [main]: impl.YarnClientImpl (YarnClientImpl.java:submitApplication(236)) - Submitted application application_1427857797694_0001
2015-03-31 23:13:29,902 INFO  [main]: mapreduce.Job (Job.java:submit(1289)) - The url to track the job: http://k05n26:8088/proxy/application_1427857797694_0001/
2015-03-31 23:13:29,903 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Starting Job = job_1427857797694_0001, Tracking URL = http://k05n26:8088/proxy/application_1427857797694_0001/
2015-03-31 23:13:29,903 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Kill Command = /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop job  -kill job_1427857797694_0001
2015-03-31 23:13:37,100 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Hadoop job information for Stage-1: number of mappers: 0; number of reducers: 0
2015-03-31 23:13:37,178 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2015-03-31 23:13:37,178 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:13:37,176 Stage-1 map = 0%,  reduce = 0%
2015-03-31 23:13:38,206 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2015-03-31 23:13:38,224 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Ended Job = job_1427857797694_0001
2015-03-31 23:13:38,233 INFO  [main]: exec.FileSinkOperator (Utilities.java:mvFileToFinalPath(1805)) - Moving tmp dir: hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1/_tmp.-ext-10002 to: hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1/-ext-10002
2015-03-31 23:13:38,239 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.CONDITION.Stage-7 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,239 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-7:CONDITIONAL] in serial mode
2015-03-31 23:13:38,241 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Stage-4 is selected by condition resolver.
2015-03-31 23:13:38,241 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Stage-3 is filtered out by condition resolver.
2015-03-31 23:13:38,242 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Stage-5 is filtered out by condition resolver.
2015-03-31 23:13:38,242 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MOVE.Stage-4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,242 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-4:MOVE] in serial mode
2015-03-31 23:13:38,242 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Moving data to: hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1/-ext-10000 from hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1/-ext-10002
2015-03-31 23:13:38,245 INFO  [main]: metadata.Hive (Hive.java:renameFile(2359)) - Replacing src:hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1/-ext-10002;dest: hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1/-ext-10000;Status:true
2015-03-31 23:13:38,245 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MOVE.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,245 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:MOVE] in serial mode
2015-03-31 23:13:38,245 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Loading data to table default.reqddata from hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1/-ext-10000
2015-03-31 23:13:38,246 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:13:38,246 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:13:38,260 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:13:38,260 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:13:38,279 INFO  [main]: metadata.Hive (Hive.java:renameFile(2359)) - Replacing src:hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1/-ext-10000;dest: hdfs://k05n26:54310/user/hive/warehouse/reqddata;Status:true
2015-03-31 23:13:38,280 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: alter_table: db=default tbl=reqddata newtbl=reqddata
2015-03-31 23:13:38,280 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=reqddata newtbl=reqddata	
2015-03-31 23:13:38,303 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for reqddata
2015-03-31 23:13:38,304 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table reqddata to 0
2015-03-31 23:13:38,333 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.STATS.Stage-2 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,333 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-2:STATS] in serial mode
2015-03-31 23:13:38,333 INFO  [main]: exec.StatsTask (StatsTask.java:execute(86)) - Executing stats task
2015-03-31 23:13:38,334 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:13:38,334 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:13:38,347 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-27_893_1119470055326645968-1/-ext-10001
2015-03-31 23:13:38,349 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:13:38,349 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:13:38,361 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.reqddata/	numRows	0
2015-03-31 23:13:38,361 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.reqddata/	rawDataSize	0
2015-03-31 23:13:38,363 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: alter_table: db=default tbl=reqddata newtbl=reqddata
2015-03-31 23:13:38,363 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=reqddata newtbl=reqddata	
2015-03-31 23:13:38,387 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for reqddata
2015-03-31 23:13:38,387 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table reqddata to 0
2015-03-31 23:13:38,399 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Table default.reqddata stats: [numFiles=0, numRows=0, totalSize=0, rawDataSize=0]
2015-03-31 23:13:38,401 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427858008603 end=1427858018401 duration=9798 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,401 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427858008602 end=1427858018401 duration=9799 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,401 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - MapReduce Jobs Launched: 
2015-03-31 23:13:38,405 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2015-03-31 23:13:38,406 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2015-03-31 23:13:38,406 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total MapReduce CPU Time Spent: 0 msec
2015-03-31 23:13:38,406 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:13:38,406 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,406 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427858018406 end=1427858018406 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,407 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427858007892 end=1427858018407 duration=10515 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,408 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 10.515 seconds
2015-03-31 23:13:38,408 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,408 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,408 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:13:38,408 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,409 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,409 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 

drop table begin
2015-03-31 23:13:38,409 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:13:38,409 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427858018409 end=1427858018409 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,410 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,410 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=begin
2015-03-31 23:13:38,410 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=begin	
2015-03-31 23:13:38,412 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:13:38,412 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427858018410 end=1427858018412 duration=2 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,412 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:13:38,412 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427858018408 end=1427858018412 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,412 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,412 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 

drop table begin
2015-03-31 23:13:38,412 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427858018408 end=1427858018412 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,413 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,413 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,413 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:13:38,413 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=begin
2015-03-31 23:13:38,414 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=begin	
2015-03-31 23:13:38,414 ERROR [main]: metadata.Hive (Hive.java:getTable(1063)) - Table begin not found: default.begin table not found
2015-03-31 23:13:38,415 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=begin
2015-03-31 23:13:38,415 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=begin	
2015-03-31 23:13:38,416 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427858018413 end=1427858018416 duration=3 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,416 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427858018412 end=1427858018416 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,416 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:13:38,416 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,416 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427858018416 end=1427858018416 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,417 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427858018408 end=1427858018417 duration=9 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,417 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.0090 seconds
2015-03-31 23:13:38,417 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,417 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,417 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:13:38,417 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,418 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,418 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: create table begin as
select stock_name, min(stock_date) as stock_date, month
from reqddata
group by stock_name, month
2015-03-31 23:13:38,421 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:13:38,421 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427858018418 end=1427858018421 duration=3 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,421 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,422 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:13:38,422 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeCreateTable(10828)) - Creating table default.begin position=13
2015-03-31 23:13:38,422 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:13:38,422 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:13:38,424 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=begin
2015-03-31 23:13:38,424 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=begin	
2015-03-31 23:13:38,426 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10000)) - Completed phase 1 of Semantic Analysis
2015-03-31 23:13:38,426 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1554)) - Get metadata for source tables
2015-03-31 23:13:38,426 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:13:38,426 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:13:38,438 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1702)) - Get metadata for subqueries
2015-03-31 23:13:38,438 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1726)) - Get metadata for destination tables
2015-03-31 23:13:38,439 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:13:38,439 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:13:38,443 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10003)) - Completed getting MetaData in Semantic Analysis
2015-03-31 23:13:38,462 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:genFileSinkPlan(6412)) - Set stats collection dir : hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-38_418_6148496046273617337-1/-ext-10002
2015-03-31 23:13:38,467 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for FS(6)
2015-03-31 23:13:38,468 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(5)
2015-03-31 23:13:38,468 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for GBY(4)
2015-03-31 23:13:38,468 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for RS(3)
2015-03-31 23:13:38,468 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for GBY(2)
2015-03-31 23:13:38,468 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(1)
2015-03-31 23:13:38,468 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(0)
2015-03-31 23:13:38,471 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(761)) - RS 3 oldColExprMap: {KEY._col0=Column[_col0], KEY._col1=Column[_col1], VALUE._col0=Column[_col2]}
2015-03-31 23:13:38,472 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(812)) - RS 3 newColExprMap: {KEY._col0=Column[_col0], KEY._col1=Column[_col1], VALUE._col0=Column[_col2]}
2015-03-31 23:13:38,473 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:13:38,474 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:13:38,475 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:13:38,475 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:13:38,477 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:13:38,478 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427858018477 end=1427858018478 duration=1 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:13:38,479 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:13:38,479 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:13:38,479 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:13:38,479 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:13:38,480 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:13:38,480 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:13:38,481 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10173)) - Completed plan generation
2015-03-31 23:13:38,481 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:13:38,481 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427858018421 end=1427858018481 duration=60 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,481 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:month, type:string, comment:null)], properties:null)
2015-03-31 23:13:38,481 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427858018417 end=1427858018481 duration=64 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,481 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,482 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: create table begin as
select stock_name, min(stock_date) as stock_date, month
from reqddata
group by stock_name, month
2015-03-31 23:13:38,482 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Query ID = u2_20150331231313_2749393a-6c3d-4cb7-bba8-bbe59dc26c13
2015-03-31 23:13:38,482 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total jobs = 1
2015-03-31 23:13:38,482 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427858018417 end=1427858018482 duration=65 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,482 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,482 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPRED.Stage-1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:13:38,483 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Launching Job 1 out of 1
2015-03-31 23:13:38,484 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-1:MAPRED] in serial mode
2015-03-31 23:13:38,484 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getInputSummary from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:13:38,501 INFO  [main]: exec.Utilities (Utilities.java:getInputSummary(2562)) - Cache Content Summary for hdfs://k05n26:54310/user/hive/warehouse/reqddata length: 0 file count: 0 directory count: 1
2015-03-31 23:13:38,501 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getInputSummary start=1427858018484 end=1427858018501 duration=17 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:13:38,501 INFO  [main]: exec.Utilities (Utilities.java:estimateNumberOfReducers(3119)) - BytesPerReducer=256000000 maxReducers=1009 totalInputFileSize=0
2015-03-31 23:13:38,501 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Number of reduce tasks not specified. Estimated from input data size: 1
2015-03-31 23:13:38,501 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to change the average load for a reducer (in bytes):
2015-03-31 23:13:38,501 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set hive.exec.reducers.bytes.per.reducer=<number>
2015-03-31 23:13:38,502 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to limit the maximum number of reducers:
2015-03-31 23:13:38,502 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set hive.exec.reducers.max=<number>
2015-03-31 23:13:38,502 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to set a constant number of reducers:
2015-03-31 23:13:38,502 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set mapreduce.job.reduces=<number>
2015-03-31 23:13:38,502 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-38_418_6148496046273617337-1
2015-03-31 23:13:38,504 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(287)) - Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2015-03-31 23:13:38,504 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3265)) - Processing alias reqddata
2015-03-31 23:13:38,504 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3282)) - Adding input file hdfs://k05n26:54310/user/hive/warehouse/reqddata
2015-03-31 23:13:38,504 INFO  [main]: exec.Utilities (Utilities.java:isEmptyPath(2601)) - Content Summary hdfs://k05n26:54310/user/hive/warehouse/reqddatalength: 0 num files: 0 num directories: 1
2015-03-31 23:13:38,510 INFO  [main]: exec.Utilities (Utilities.java:createDummyFileForEmptyPartition(3365)) - Changed input file to hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-38_418_6148496046273617337-1/-mr-10003/0
2015-03-31 23:13:38,510 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-38_418_6148496046273617337-1
2015-03-31 23:13:38,513 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:13:38,514 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapWork via kryo
2015-03-31 23:13:38,530 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427858018513 end=1427858018530 duration=17 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:13:38,533 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:13:38,533 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing ReduceWork via kryo
2015-03-31 23:13:38,543 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427858018533 end=1427858018543 duration=10 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:13:38,559 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n26/10.111.5.26:8032
2015-03-31 23:13:38,562 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-38_418_6148496046273617337-1/-ext-10002
2015-03-31 23:13:38,577 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n26/10.111.5.26:8032
2015-03-31 23:13:38,585 WARN  [main]: mapreduce.JobSubmitter (JobSubmitter.java:copyAndConfigureFiles(150)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-03-31 23:13:38,668 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:13:38,670 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(387)) - CombineHiveInputSplit creating pool for hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-38_418_6148496046273617337-1/-mr-10003/0; using filter path hdfs://k05n26:54310/tmp/hive/u2/c7e988b4-54b2-4b89-b7f4-52d3f8935901/hive_2015-03-31_23-13-38_418_6148496046273617337-1/-mr-10003/0
2015-03-31 23:13:38,674 INFO  [main]: input.FileInputFormat (FileInputFormat.java:listStatus(281)) - Total input paths to process : 1
2015-03-31 23:13:38,674 INFO  [main]: input.CombineFileInputFormat (CombineFileInputFormat.java:createSplits(413)) - DEBUG: Terminated node allocation with : CompletedNodes: 0, size left: 0
2015-03-31 23:13:38,679 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(442)) - number of splits 1
2015-03-31 23:13:38,679 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getSplits start=1427858018668 end=1427858018679 duration=11 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:13:38,679 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(521)) - Number of all splits 1
2015-03-31 23:13:38,696 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(396)) - number of splits:1
2015-03-31 23:13:38,730 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:printTokens(479)) - Submitting tokens for job: job_1427857797694_0002
2015-03-31 23:13:38,743 INFO  [main]: impl.YarnClientImpl (YarnClientImpl.java:submitApplication(236)) - Submitted application application_1427857797694_0002
2015-03-31 23:13:38,746 INFO  [main]: mapreduce.Job (Job.java:submit(1289)) - The url to track the job: http://k05n26:8088/proxy/application_1427857797694_0002/
2015-03-31 23:13:38,746 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Starting Job = job_1427857797694_0002, Tracking URL = http://k05n26:8088/proxy/application_1427857797694_0002/
2015-03-31 23:13:38,747 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Kill Command = /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop job  -kill job_1427857797694_0002
2015-03-31 23:35:26,763 WARN  [main]: common.LogUtils (LogUtils.java:logConfigLocation(140)) - DEPRECATED: Ignoring hive-default.xml found on the CLASSPATH at /gpfs/courses/cse587/spring2015/students/u2/hw3/hive_official/src/config-3611420/hive-default.xml
2015-03-31 23:35:26,794 WARN  [main]: common.LogUtils (LogUtils.java:logConfigLocation(145)) - hive-site.xml not found on CLASSPATH
2015-03-31 23:35:26,925 INFO  [main]: SessionState (SessionState.java:printInfo(824)) - 
Logging initialized using configuration in file:/gpfs/courses/cse587/spring2015/students/u2/hw3/hive_official/src/config-3611420/hive-log4j.properties
2015-03-31 23:35:27,100 WARN  [main]: util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(62)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-31 23:35:27,157 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:newRawStore(556)) - 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
2015-03-31 23:35:27,182 INFO  [main]: metastore.ObjectStore (ObjectStore.java:initialize(264)) - ObjectStore, initialize called
2015-03-31 23:35:36,991 INFO  [main]: metastore.ObjectStore (ObjectStore.java:getPMF(345)) - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2015-03-31 23:35:37,130 INFO  [main]: metastore.MetaStoreDirectSql (MetaStoreDirectSql.java:<init>(109)) - MySQL check failed, assuming we are not on mysql: Lexical error at line 1, column 5.  Encountered: "@" (64), after : "".
2015-03-31 23:35:49,286 INFO  [main]: metastore.ObjectStore (ObjectStore.java:setConf(247)) - Initialized ObjectStore
2015-03-31 23:35:49,714 WARN  [main]: metastore.ObjectStore (ObjectStore.java:checkSchema(6570)) - Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 0.14.0
2015-03-31 23:35:50,240 WARN  [main]: metastore.ObjectStore (ObjectStore.java:getDatabase(538)) - Failed to get database default, returning NoSuchObjectException
2015-03-31 23:35:51,658 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:createDefaultRoles_core(630)) - Added admin role in metastore
2015-03-31 23:35:51,663 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:createDefaultRoles_core(639)) - Added public role in metastore
2015-03-31 23:35:52,034 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:addAdminUsers_core(679)) - No user is added in admin role, since config is empty
2015-03-31 23:35:52,576 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created HDFS directory: /tmp/hive/u2
2015-03-31 23:35:52,626 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created local directory: /tmp/909943e7-06d0-467b-836c-1fae91405551_resources
2015-03-31 23:35:52,703 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created HDFS directory: /tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551
2015-03-31 23:35:52,746 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created local directory: /tmp/u2/909943e7-06d0-467b-836c-1fae91405551
2015-03-31 23:35:52,750 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created HDFS directory: /tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/_tmp_space.db
2015-03-31 23:35:52,753 INFO  [main]: session.SessionState (SessionState.java:start(460)) - No Tez session required at this point. hive.execution.engine=mr.
2015-03-31 23:35:52,812 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:52,812 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:52,813 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:35:52,813 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:52,883 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:52,890 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: DROP table stock_prices
2015-03-31 23:35:53,362 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:35:53,366 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859352883 end=1427859353366 duration=483 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,373 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,440 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=stock_prices
2015-03-31 23:35:53,441 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=stock_prices	
2015-03-31 23:35:53,524 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:35:53,524 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859353373 end=1427859353524 duration=151 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,542 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:35:53,543 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859352813 end=1427859353543 duration=730 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,543 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,543 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: DROP table stock_prices
2015-03-31 23:35:53,551 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859352812 end=1427859353551 duration=739 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,551 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,551 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,562 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:35:53,564 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=stock_prices
2015-03-31 23:35:53,564 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=stock_prices	
2015-03-31 23:35:53,567 ERROR [main]: metadata.Hive (Hive.java:getTable(1063)) - Table stock_prices not found: default.stock_prices table not found
2015-03-31 23:35:53,583 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=stock_prices
2015-03-31 23:35:53,583 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=stock_prices	
2015-03-31 23:35:53,586 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859353551 end=1427859353586 duration=35 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,587 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859353543 end=1427859353587 duration=44 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,588 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:35:53,589 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,589 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859353589 end=1427859353589 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,590 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859352812 end=1427859353590 duration=778 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,593 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.785 seconds
2015-03-31 23:35:53,594 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,594 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,594 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:35:53,594 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,596 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,597 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command:  CREATE EXTERNAL TABLE stock_prices (stock_date STRING, Open FLOAT, High FLOAT, Low FLOAT, Close FLOAT, Volume FLOAT, Adj_Close FLOAT)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n'
STORED AS TEXTFILE
LOCATION '/user/'
tblproperties ("skip.header.line.count"="1")
2015-03-31 23:35:53,616 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:35:53,616 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859353596 end=1427859353616 duration=20 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,617 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,671 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:35:53,683 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeCreateTable(10828)) - Creating table default.stock_prices position=23
2015-03-31 23:35:53,698 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:35:53,698 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:35:53,752 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:35:53,753 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859353617 end=1427859353753 duration=136 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,753 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:35:53,754 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859353594 end=1427859353754 duration=160 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,754 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,754 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command:  CREATE EXTERNAL TABLE stock_prices (stock_date STRING, Open FLOAT, High FLOAT, Low FLOAT, Close FLOAT, Volume FLOAT, Adj_Close FLOAT)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n'
STORED AS TEXTFILE
LOCATION '/user/'
tblproperties ("skip.header.line.count"="1")
2015-03-31 23:35:53,755 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859353594 end=1427859353755 duration=161 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,755 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,755 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,756 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:35:53,816 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: create_table: Table(tableName:stock_prices, dbName:default, owner:u2, createTime:1427859353, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:open, type:float, comment:null), FieldSchema(name:high, type:float, comment:null), FieldSchema(name:low, type:float, comment:null), FieldSchema(name:close, type:float, comment:null), FieldSchema(name:volume, type:float, comment:null), FieldSchema(name:adj_close, type:float, comment:null)], location:/user, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{line.delim=
, serialization.format=,, field.delim=,}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{EXTERNAL=TRUE, skip.header.line.count=1}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2015-03-31 23:35:53,817 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=create_table: Table(tableName:stock_prices, dbName:default, owner:u2, createTime:1427859353, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:open, type:float, comment:null), FieldSchema(name:high, type:float, comment:null), FieldSchema(name:low, type:float, comment:null), FieldSchema(name:close, type:float, comment:null), FieldSchema(name:volume, type:float, comment:null), FieldSchema(name:adj_close, type:float, comment:null)], location:/user, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{line.delim=
, serialization.format=,, field.delim=,}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{EXTERNAL=TRUE, skip.header.line.count=1}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2015-03-31 23:35:53,825 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for stock_prices
2015-03-31 23:35:53,825 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table stock_prices to 0
2015-03-31 23:35:53,920 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859353755 end=1427859353920 duration=165 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,920 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859353754 end=1427859353920 duration=166 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,921 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:35:53,921 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,921 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859353921 end=1427859353921 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,921 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859353594 end=1427859353921 duration=327 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,922 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.329 seconds
2015-03-31 23:35:53,922 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,922 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,922 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:35:53,922 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,923 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,923 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 


drop table reqddata
2015-03-31 23:35:53,924 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:35:53,924 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859353923 end=1427859353924 duration=1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,924 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,925 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:35:53,925 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:35:53,926 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:35:53,926 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859353924 end=1427859353926 duration=2 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,926 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:35:53,926 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859353922 end=1427859353926 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,926 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,927 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 


drop table reqddata
2015-03-31 23:35:53,927 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859353922 end=1427859353927 duration=5 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,927 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,927 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,927 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:35:53,928 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:35:53,928 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:35:53,929 ERROR [main]: metadata.Hive (Hive.java:getTable(1063)) - Table reqddata not found: default.reqddata table not found
2015-03-31 23:35:53,945 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:35:53,945 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:35:53,946 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859353927 end=1427859353946 duration=19 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,946 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859353926 end=1427859353946 duration=20 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,947 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:35:53,947 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,947 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859353947 end=1427859353947 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,947 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859353922 end=1427859353947 duration=25 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,947 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.025 seconds
2015-03-31 23:35:53,947 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,947 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,948 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:35:53,948 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,948 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,948 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: create table reqddata(stock_name STRING, stock_date STRING, month STRING, Adj_Close FLOAT)
2015-03-31 23:35:53,949 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:35:53,949 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859353948 end=1427859353949 duration=1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,949 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,950 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:35:53,950 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeCreateTable(10828)) - Creating table default.reqddata position=13
2015-03-31 23:35:53,950 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:35:53,950 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:35:53,952 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:35:53,952 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859353949 end=1427859353952 duration=3 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,952 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:35:53,953 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859353948 end=1427859353953 duration=5 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,953 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,953 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: create table reqddata(stock_name STRING, stock_date STRING, month STRING, Adj_Close FLOAT)
2015-03-31 23:35:53,954 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859353947 end=1427859353954 duration=7 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,954 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,954 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,954 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:35:53,957 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: create_table: Table(tableName:reqddata, dbName:default, owner:u2, createTime:1427859353, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:month, type:string, comment:null), FieldSchema(name:adj_close, type:float, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2015-03-31 23:35:53,957 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=create_table: Table(tableName:reqddata, dbName:default, owner:u2, createTime:1427859353, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:month, type:string, comment:null), FieldSchema(name:adj_close, type:float, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2015-03-31 23:35:53,961 INFO  [main]: common.FileUtils (FileUtils.java:mkdir(504)) - Creating directory if it doesn't exist: hdfs://k05n22:54310/user/hive/warehouse/reqddata
2015-03-31 23:35:53,982 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859353954 end=1427859353982 duration=28 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,983 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859353953 end=1427859353983 duration=30 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,983 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:35:53,983 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,983 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859353983 end=1427859353983 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,983 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859353947 end=1427859353983 duration=36 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,984 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.037 seconds
2015-03-31 23:35:53,984 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,984 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,984 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:35:53,984 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,985 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:53,985 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 
insert overwrite table reqddata select regexp_replace( regexp_replace(INPUT__FILE__NAME,'.*/',''),'\\..*','') as stock_name, stock_date, substr(stock_date,0,7) as month, Adj_Close from stock_prices
2015-03-31 23:35:54,002 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:35:54,003 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859353985 end=1427859354003 duration=18 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:54,003 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:54,003 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:35:54,675 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10000)) - Completed phase 1 of Semantic Analysis
2015-03-31 23:35:54,675 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1554)) - Get metadata for source tables
2015-03-31 23:35:54,675 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=stock_prices
2015-03-31 23:35:54,675 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=stock_prices	
2015-03-31 23:35:54,855 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1702)) - Get metadata for subqueries
2015-03-31 23:35:54,856 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1726)) - Get metadata for destination tables
2015-03-31 23:35:54,857 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:35:54,857 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:35:54,870 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10003)) - Completed getting MetaData in Semantic Analysis
2015-03-31 23:35:54,946 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:genFileSinkPlan(6412)) - Set stats collection dir : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1/-ext-10001
2015-03-31 23:35:55,008 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for FS(2)
2015-03-31 23:35:55,009 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(1)
2015-03-31 23:35:55,009 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(0)
2015-03-31 23:35:55,060 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:35:55,063 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427859355060 end=1427859355063 duration=3 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:35:55,065 INFO  [main]: optimizer.GenMRFileSink1 (GenMRFileSink1.java:process(103)) - using CombineHiveInputformat for the merge job
2015-03-31 23:35:55,081 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:35:55,082 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:35:55,082 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:35:55,082 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:35:55,083 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:35:55,084 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:35:55,085 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10173)) - Completed plan generation
2015-03-31 23:35:55,085 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:35:55,086 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859354003 end=1427859355086 duration=1083 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:55,086 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:month, type:string, comment:null), FieldSchema(name:adj_close, type:float, comment:null)], properties:null)
2015-03-31 23:35:55,086 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859353984 end=1427859355086 duration=1102 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:55,086 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:55,086 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 
insert overwrite table reqddata select regexp_replace( regexp_replace(INPUT__FILE__NAME,'.*/',''),'\\..*','') as stock_name, stock_date, substr(stock_date,0,7) as month, Adj_Close from stock_prices
2015-03-31 23:35:55,086 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Query ID = u2_20150331233535_d6efbd3a-9069-4d5d-b366-b3f07281a9de
2015-03-31 23:35:55,087 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total jobs = 3
2015-03-31 23:35:55,087 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859353984 end=1427859355087 duration=1103 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:55,087 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:55,087 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPRED.Stage-1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:35:55,100 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Launching Job 1 out of 3
2015-03-31 23:35:55,103 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-1:MAPRED] in serial mode
2015-03-31 23:35:55,103 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Number of reduce tasks is set to 0 since there's no reduce operator
2015-03-31 23:35:55,104 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1
2015-03-31 23:35:55,112 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(287)) - Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2015-03-31 23:35:55,117 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3265)) - Processing alias stock_prices
2015-03-31 23:35:55,117 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3282)) - Adding input file hdfs://k05n22:54310/user
2015-03-31 23:35:55,117 INFO  [main]: exec.Utilities (Utilities.java:isEmptyPath(2605)) - Content Summary not cached for hdfs://k05n22:54310/user
2015-03-31 23:35:55,120 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1
2015-03-31 23:35:55,138 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:35:55,139 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapWork via kryo
2015-03-31 23:35:55,493 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859355138 end=1427859355493 duration=355 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:35:55,495 INFO  [main]: Configuration.deprecation (Configuration.java:warnOnceIfDeprecated(1019)) - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication
2015-03-31 23:35:55,618 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:35:55,858 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1/-ext-10001
2015-03-31 23:35:55,913 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:35:55,926 INFO  [main]: exec.Utilities (Utilities.java:getBaseWork(419)) - No plan file found: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1/-mr-10004/5f5f3573-8f91-4518-be3d-af5e75ece75f/reduce.xml
2015-03-31 23:35:56,660 WARN  [main]: mapreduce.JobSubmitter (JobSubmitter.java:copyAndConfigureFiles(150)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-03-31 23:35:56,939 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:35:56,964 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(387)) - CombineHiveInputSplit creating pool for hdfs://k05n22:54310/user; using filter path hdfs://k05n22:54310/user
2015-03-31 23:35:56,980 INFO  [main]: input.FileInputFormat (FileInputFormat.java:listStatus(281)) - Total input paths to process : 1
2015-03-31 23:35:56,986 INFO  [main]: input.CombineFileInputFormat (CombineFileInputFormat.java:createSplits(413)) - DEBUG: Terminated node allocation with : CompletedNodes: 0, size left: 0
2015-03-31 23:35:56,991 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(442)) - number of splits 0
2015-03-31 23:35:56,992 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getSplits start=1427859356939 end=1427859356992 duration=53 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:35:56,994 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(521)) - Number of all splits 0
2015-03-31 23:35:57,045 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(396)) - number of splits:0
2015-03-31 23:35:57,217 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:printTokens(479)) - Submitting tokens for job: job_1427859192785_0001
2015-03-31 23:35:57,865 INFO  [main]: impl.YarnClientImpl (YarnClientImpl.java:submitApplication(236)) - Submitted application application_1427859192785_0001
2015-03-31 23:35:57,941 INFO  [main]: mapreduce.Job (Job.java:submit(1289)) - The url to track the job: http://k05n22:8088/proxy/application_1427859192785_0001/
2015-03-31 23:35:57,943 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Starting Job = job_1427859192785_0001, Tracking URL = http://k05n22:8088/proxy/application_1427859192785_0001/
2015-03-31 23:35:57,944 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Kill Command = /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop job  -kill job_1427859192785_0001
2015-03-31 23:36:11,301 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Hadoop job information for Stage-1: number of mappers: 0; number of reducers: 0
2015-03-31 23:36:11,384 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2015-03-31 23:36:11,385 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:36:11,379 Stage-1 map = 0%,  reduce = 0%
2015-03-31 23:36:13,559 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2015-03-31 23:36:13,594 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Ended Job = job_1427859192785_0001
2015-03-31 23:36:13,626 INFO  [main]: exec.FileSinkOperator (Utilities.java:mvFileToFinalPath(1805)) - Moving tmp dir: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1/_tmp.-ext-10002 to: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1/-ext-10002
2015-03-31 23:36:13,636 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.CONDITION.Stage-7 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:13,638 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-7:CONDITIONAL] in serial mode
2015-03-31 23:36:13,642 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Stage-4 is selected by condition resolver.
2015-03-31 23:36:13,642 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Stage-3 is filtered out by condition resolver.
2015-03-31 23:36:13,642 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Stage-5 is filtered out by condition resolver.
2015-03-31 23:36:13,643 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MOVE.Stage-4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:13,643 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-4:MOVE] in serial mode
2015-03-31 23:36:13,644 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Moving data to: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1/-ext-10000 from hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1/-ext-10002
2015-03-31 23:36:13,649 INFO  [main]: metadata.Hive (Hive.java:renameFile(2359)) - Replacing src:hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1/-ext-10002;dest: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1/-ext-10000;Status:true
2015-03-31 23:36:13,650 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MOVE.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:13,650 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:MOVE] in serial mode
2015-03-31 23:36:13,651 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Loading data to table default.reqddata from hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1/-ext-10000
2015-03-31 23:36:13,651 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:36:13,652 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:36:13,681 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:36:13,682 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:36:13,726 INFO  [main]: metadata.Hive (Hive.java:renameFile(2359)) - Replacing src:hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1/-ext-10000;dest: hdfs://k05n22:54310/user/hive/warehouse/reqddata;Status:true
2015-03-31 23:36:13,727 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: alter_table: db=default tbl=reqddata newtbl=reqddata
2015-03-31 23:36:13,728 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=reqddata newtbl=reqddata	
2015-03-31 23:36:13,784 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for reqddata
2015-03-31 23:36:13,784 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table reqddata to 0
2015-03-31 23:36:13,851 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.STATS.Stage-2 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:13,852 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-2:STATS] in serial mode
2015-03-31 23:36:13,852 INFO  [main]: exec.StatsTask (StatsTask.java:execute(86)) - Executing stats task
2015-03-31 23:36:13,853 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:36:13,854 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:36:13,884 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-35-53_985_6396214291143412452-1/-ext-10001
2015-03-31 23:36:13,888 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:36:13,888 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:36:13,917 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.reqddata/	numRows	0
2015-03-31 23:36:13,917 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.reqddata/	rawDataSize	0
2015-03-31 23:36:13,921 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: alter_table: db=default tbl=reqddata newtbl=reqddata
2015-03-31 23:36:13,922 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=reqddata newtbl=reqddata	
2015-03-31 23:36:13,979 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for reqddata
2015-03-31 23:36:13,980 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table reqddata to 0
2015-03-31 23:36:14,003 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Table default.reqddata stats: [numFiles=0, numRows=0, totalSize=0, rawDataSize=0]
2015-03-31 23:36:14,006 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859355087 end=1427859374006 duration=18919 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,006 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859355086 end=1427859374006 duration=18920 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,007 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - MapReduce Jobs Launched: 
2015-03-31 23:36:14,014 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2015-03-31 23:36:14,016 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 SUCCESS
2015-03-31 23:36:14,017 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total MapReduce CPU Time Spent: 0 msec
2015-03-31 23:36:14,017 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:36:14,017 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,018 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859374017 end=1427859374017 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,018 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859353984 end=1427859374018 duration=20034 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,021 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 20.034 seconds
2015-03-31 23:36:14,021 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,022 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,022 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:36:14,022 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,024 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,024 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 

drop table begin
2015-03-31 23:36:14,024 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:36:14,025 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859374024 end=1427859374025 duration=1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,025 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,026 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=begin
2015-03-31 23:36:14,027 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=begin	
2015-03-31 23:36:14,029 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:36:14,029 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859374025 end=1427859374029 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,048 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:36:14,049 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859374022 end=1427859374049 duration=27 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,049 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,049 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 

drop table begin
2015-03-31 23:36:14,050 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859374022 end=1427859374050 duration=28 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,050 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,050 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,051 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:36:14,052 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=begin
2015-03-31 23:36:14,052 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=begin	
2015-03-31 23:36:14,055 ERROR [main]: metadata.Hive (Hive.java:getTable(1063)) - Table begin not found: default.begin table not found
2015-03-31 23:36:14,055 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=begin
2015-03-31 23:36:14,056 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=begin	
2015-03-31 23:36:14,058 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859374050 end=1427859374058 duration=8 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,058 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859374049 end=1427859374058 duration=9 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,059 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:36:14,059 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,059 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859374059 end=1427859374059 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,059 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859374021 end=1427859374059 duration=38 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,060 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.039 seconds
2015-03-31 23:36:14,060 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,061 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,061 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:36:14,061 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,062 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,063 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: create table begin as
select stock_name, min(stock_date) as stock_date, month
from reqddata
group by stock_name, month
2015-03-31 23:36:14,081 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:36:14,081 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859374062 end=1427859374081 duration=19 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,081 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,082 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:36:14,083 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeCreateTable(10828)) - Creating table default.begin position=13
2015-03-31 23:36:14,083 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:36:14,084 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:36:14,088 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=begin
2015-03-31 23:36:14,088 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=begin	
2015-03-31 23:36:14,091 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10000)) - Completed phase 1 of Semantic Analysis
2015-03-31 23:36:14,091 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1554)) - Get metadata for source tables
2015-03-31 23:36:14,091 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:36:14,092 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:36:14,120 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1702)) - Get metadata for subqueries
2015-03-31 23:36:14,121 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1726)) - Get metadata for destination tables
2015-03-31 23:36:14,121 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:36:14,122 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:36:14,129 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10003)) - Completed getting MetaData in Semantic Analysis
2015-03-31 23:36:14,171 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:genFileSinkPlan(6412)) - Set stats collection dir : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-14_062_1715703969561957169-1/-ext-10002
2015-03-31 23:36:14,181 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for FS(6)
2015-03-31 23:36:14,182 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(5)
2015-03-31 23:36:14,182 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for GBY(4)
2015-03-31 23:36:14,182 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for RS(3)
2015-03-31 23:36:14,183 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for GBY(2)
2015-03-31 23:36:14,183 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(1)
2015-03-31 23:36:14,183 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(0)
2015-03-31 23:36:14,190 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(761)) - RS 3 oldColExprMap: {KEY._col0=Column[_col0], KEY._col1=Column[_col1], VALUE._col0=Column[_col2]}
2015-03-31 23:36:14,190 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(812)) - RS 3 newColExprMap: {KEY._col0=Column[_col0], KEY._col1=Column[_col1], VALUE._col0=Column[_col2]}
2015-03-31 23:36:14,193 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:36:14,194 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:36:14,197 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:36:14,197 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:36:14,201 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:36:14,202 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427859374201 end=1427859374202 duration=1 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:36:14,204 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:36:14,205 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:36:14,205 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:36:14,205 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:36:14,206 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:36:14,206 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:36:14,208 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10173)) - Completed plan generation
2015-03-31 23:36:14,208 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:36:14,209 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859374081 end=1427859374209 duration=128 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,209 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:month, type:string, comment:null)], properties:null)
2015-03-31 23:36:14,209 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859374061 end=1427859374209 duration=148 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,210 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,210 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: create table begin as
select stock_name, min(stock_date) as stock_date, month
from reqddata
group by stock_name, month
2015-03-31 23:36:14,210 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Query ID = u2_20150331233636_67e96172-94a7-450f-94d4-f93faa7415e5
2015-03-31 23:36:14,211 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total jobs = 1
2015-03-31 23:36:14,211 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859374061 end=1427859374211 duration=150 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,211 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,211 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPRED.Stage-1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:14,212 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Launching Job 1 out of 1
2015-03-31 23:36:14,214 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-1:MAPRED] in serial mode
2015-03-31 23:36:14,214 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getInputSummary from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:36:14,252 INFO  [main]: exec.Utilities (Utilities.java:getInputSummary(2562)) - Cache Content Summary for hdfs://k05n22:54310/user/hive/warehouse/reqddata length: 0 file count: 0 directory count: 1
2015-03-31 23:36:14,252 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getInputSummary start=1427859374214 end=1427859374252 duration=38 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:36:14,252 INFO  [main]: exec.Utilities (Utilities.java:estimateNumberOfReducers(3119)) - BytesPerReducer=256000000 maxReducers=1009 totalInputFileSize=0
2015-03-31 23:36:14,253 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Number of reduce tasks not specified. Estimated from input data size: 1
2015-03-31 23:36:14,253 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to change the average load for a reducer (in bytes):
2015-03-31 23:36:14,254 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set hive.exec.reducers.bytes.per.reducer=<number>
2015-03-31 23:36:14,254 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to limit the maximum number of reducers:
2015-03-31 23:36:14,254 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set hive.exec.reducers.max=<number>
2015-03-31 23:36:14,255 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to set a constant number of reducers:
2015-03-31 23:36:14,255 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set mapreduce.job.reduces=<number>
2015-03-31 23:36:14,255 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-14_062_1715703969561957169-1
2015-03-31 23:36:14,258 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(287)) - Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2015-03-31 23:36:14,258 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3265)) - Processing alias reqddata
2015-03-31 23:36:14,259 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3282)) - Adding input file hdfs://k05n22:54310/user/hive/warehouse/reqddata
2015-03-31 23:36:14,259 INFO  [main]: exec.Utilities (Utilities.java:isEmptyPath(2601)) - Content Summary hdfs://k05n22:54310/user/hive/warehouse/reqddatalength: 0 num files: 0 num directories: 1
2015-03-31 23:36:14,269 INFO  [main]: exec.Utilities (Utilities.java:createDummyFileForEmptyPartition(3365)) - Changed input file to hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-14_062_1715703969561957169-1/-mr-10003/0
2015-03-31 23:36:14,270 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-14_062_1715703969561957169-1
2015-03-31 23:36:14,275 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:36:14,275 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapWork via kryo
2015-03-31 23:36:14,307 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859374275 end=1427859374307 duration=32 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:36:14,312 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:36:14,312 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing ReduceWork via kryo
2015-03-31 23:36:14,331 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859374312 end=1427859374331 duration=19 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:36:14,364 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:36:14,369 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-14_062_1715703969561957169-1/-ext-10002
2015-03-31 23:36:14,402 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:36:14,416 WARN  [main]: mapreduce.JobSubmitter (JobSubmitter.java:copyAndConfigureFiles(150)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-03-31 23:36:14,572 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:36:14,577 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(387)) - CombineHiveInputSplit creating pool for hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-14_062_1715703969561957169-1/-mr-10003/0; using filter path hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-14_062_1715703969561957169-1/-mr-10003/0
2015-03-31 23:36:14,584 INFO  [main]: input.FileInputFormat (FileInputFormat.java:listStatus(281)) - Total input paths to process : 1
2015-03-31 23:36:14,586 INFO  [main]: input.CombineFileInputFormat (CombineFileInputFormat.java:createSplits(413)) - DEBUG: Terminated node allocation with : CompletedNodes: 0, size left: 0
2015-03-31 23:36:14,596 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(442)) - number of splits 1
2015-03-31 23:36:14,596 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getSplits start=1427859374572 end=1427859374596 duration=24 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:36:14,596 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(521)) - Number of all splits 1
2015-03-31 23:36:14,628 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(396)) - number of splits:1
2015-03-31 23:36:14,700 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:printTokens(479)) - Submitting tokens for job: job_1427859192785_0002
2015-03-31 23:36:14,727 INFO  [main]: impl.YarnClientImpl (YarnClientImpl.java:submitApplication(236)) - Submitted application application_1427859192785_0002
2015-03-31 23:36:14,733 INFO  [main]: mapreduce.Job (Job.java:submit(1289)) - The url to track the job: http://k05n22:8088/proxy/application_1427859192785_0002/
2015-03-31 23:36:14,734 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Starting Job = job_1427859192785_0002, Tracking URL = http://k05n22:8088/proxy/application_1427859192785_0002/
2015-03-31 23:36:14,734 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Kill Command = /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop job  -kill job_1427859192785_0002
2015-03-31 23:36:26,005 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2015-03-31 23:36:26,051 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2015-03-31 23:36:26,052 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:36:26,051 Stage-1 map = 0%,  reduce = 0%
2015-03-31 23:36:32,371 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:36:32,371 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.46 sec
2015-03-31 23:36:39,720 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:36:39,719 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.72 sec
2015-03-31 23:36:40,781 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - MapReduce Total cumulative CPU time: 4 seconds 720 msec
2015-03-31 23:36:40,829 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Ended Job = job_1427859192785_0002
2015-03-31 23:36:40,850 INFO  [main]: exec.FileSinkOperator (Utilities.java:mvFileToFinalPath(1805)) - Moving tmp dir: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-14_062_1715703969561957169-1/_tmp.-ext-10001 to: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-14_062_1715703969561957169-1/-ext-10001
2015-03-31 23:36:40,855 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MOVE.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:40,856 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:MOVE] in serial mode
2015-03-31 23:36:40,856 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Moving data to: hdfs://k05n22:54310/user/hive/warehouse/begin from hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-14_062_1715703969561957169-1/-ext-10001
2015-03-31 23:36:40,860 INFO  [main]: metadata.Hive (Hive.java:renameFile(2359)) - Replacing src:hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-14_062_1715703969561957169-1/-ext-10001;dest: hdfs://k05n22:54310/user/hive/warehouse/begin;Status:true
2015-03-31 23:36:40,861 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-3 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:40,861 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-3:DDL] in serial mode
2015-03-31 23:36:40,866 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: create_table: Table(tableName:begin, dbName:default, owner:u2, createTime:1427859400, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:month, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2015-03-31 23:36:40,866 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=create_table: Table(tableName:begin, dbName:default, owner:u2, createTime:1427859400, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:stock_date, type:string, comment:null), FieldSchema(name:month, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2015-03-31 23:36:40,877 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for begin
2015-03-31 23:36:40,878 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table begin to 0
2015-03-31 23:36:40,906 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.STATS.Stage-2 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:40,907 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-2:STATS] in serial mode
2015-03-31 23:36:40,907 INFO  [main]: exec.StatsTask (StatsTask.java:execute(86)) - Executing stats task
2015-03-31 23:36:40,908 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=begin
2015-03-31 23:36:40,908 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=begin	
2015-03-31 23:36:40,937 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-14_062_1715703969561957169-1/-ext-10002
2015-03-31 23:36:41,036 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:connect(68)) - Read stats : {default.begin/={}}
2015-03-31 23:36:41,040 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.begin/	numRows	0
2015-03-31 23:36:41,040 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.begin/	rawDataSize	0
2015-03-31 23:36:41,044 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: alter_table: db=default tbl=begin newtbl=begin
2015-03-31 23:36:41,045 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=begin newtbl=begin	
2015-03-31 23:36:41,100 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for begin
2015-03-31 23:36:41,101 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table begin to 0
2015-03-31 23:36:41,123 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Table default.begin stats: [numFiles=1, numRows=0, totalSize=0, rawDataSize=0]
2015-03-31 23:36:41,125 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859374211 end=1427859401125 duration=26914 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,126 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859374210 end=1427859401126 duration=26916 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,126 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - MapReduce Jobs Launched: 
2015-03-31 23:36:41,127 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.72 sec   HDFS Read: 296 HDFS Write: 39 SUCCESS
2015-03-31 23:36:41,127 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total MapReduce CPU Time Spent: 4 seconds 720 msec
2015-03-31 23:36:41,127 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:36:41,128 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,128 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859401128 end=1427859401128 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,128 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859374060 end=1427859401128 duration=27068 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,130 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 27.068 seconds
2015-03-31 23:36:41,131 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,131 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,131 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:36:41,132 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,133 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,133 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 


drop table last
2015-03-31 23:36:41,134 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:36:41,134 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859401133 end=1427859401134 duration=1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,134 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,136 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=last
2015-03-31 23:36:41,136 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=last	
2015-03-31 23:36:41,138 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:36:41,139 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859401134 end=1427859401139 duration=5 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,139 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:36:41,139 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859401132 end=1427859401139 duration=7 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,140 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,140 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 


drop table last
2015-03-31 23:36:41,140 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859401131 end=1427859401140 duration=9 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,140 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,141 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,141 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:36:41,142 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=last
2015-03-31 23:36:41,142 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=last	
2015-03-31 23:36:41,144 ERROR [main]: metadata.Hive (Hive.java:getTable(1063)) - Table last not found: default.last table not found
2015-03-31 23:36:41,145 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=last
2015-03-31 23:36:41,145 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=last	
2015-03-31 23:36:41,148 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859401140 end=1427859401148 duration=8 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,148 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859401139 end=1427859401148 duration=9 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,148 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:36:41,148 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,149 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859401148 end=1427859401149 duration=1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,149 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859401131 end=1427859401149 duration=18 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,149 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.018 seconds
2015-03-31 23:36:41,150 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,150 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,150 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:36:41,151 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,152 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,152 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 
create table last as
select stock_name, max(stock_date) as l_stock_date, month as l_month
from reqddata
group by stock_name, month
2015-03-31 23:36:41,155 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:36:41,155 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859401152 end=1427859401155 duration=3 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,156 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,156 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:36:41,157 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeCreateTable(10828)) - Creating table default.last position=13
2015-03-31 23:36:41,157 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:36:41,158 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:36:41,162 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=last
2015-03-31 23:36:41,162 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=last	
2015-03-31 23:36:41,165 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10000)) - Completed phase 1 of Semantic Analysis
2015-03-31 23:36:41,165 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1554)) - Get metadata for source tables
2015-03-31 23:36:41,165 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:36:41,166 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:36:41,193 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1702)) - Get metadata for subqueries
2015-03-31 23:36:41,193 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1726)) - Get metadata for destination tables
2015-03-31 23:36:41,194 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:36:41,194 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:36:41,202 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10003)) - Completed getting MetaData in Semantic Analysis
2015-03-31 23:36:41,208 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:genFileSinkPlan(6412)) - Set stats collection dir : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-41_151_7970500752250191731-1/-ext-10002
2015-03-31 23:36:41,217 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for FS(6)
2015-03-31 23:36:41,218 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(5)
2015-03-31 23:36:41,218 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for GBY(4)
2015-03-31 23:36:41,219 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for RS(3)
2015-03-31 23:36:41,219 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for GBY(2)
2015-03-31 23:36:41,219 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(1)
2015-03-31 23:36:41,220 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(0)
2015-03-31 23:36:41,223 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(761)) - RS 3 oldColExprMap: {KEY._col0=Column[_col0], KEY._col1=Column[_col1], VALUE._col0=Column[_col2]}
2015-03-31 23:36:41,223 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(812)) - RS 3 newColExprMap: {KEY._col0=Column[_col0], KEY._col1=Column[_col1], VALUE._col0=Column[_col2]}
2015-03-31 23:36:41,227 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:36:41,227 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:36:41,230 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:36:41,231 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:36:41,235 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:36:41,235 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427859401235 end=1427859401235 duration=0 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:36:41,237 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:36:41,238 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:36:41,238 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:36:41,239 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:36:41,239 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:36:41,240 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:36:41,241 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10173)) - Completed plan generation
2015-03-31 23:36:41,241 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:36:41,241 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859401156 end=1427859401241 duration=85 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,242 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:l_stock_date, type:string, comment:null), FieldSchema(name:l_month, type:string, comment:null)], properties:null)
2015-03-31 23:36:41,242 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859401151 end=1427859401242 duration=91 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,242 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,243 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 
create table last as
select stock_name, max(stock_date) as l_stock_date, month as l_month
from reqddata
group by stock_name, month
2015-03-31 23:36:41,243 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Query ID = u2_20150331233636_5f72ef33-07db-4fdb-bcd8-10d71100d81d
2015-03-31 23:36:41,243 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total jobs = 1
2015-03-31 23:36:41,244 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859401150 end=1427859401244 duration=94 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,244 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,244 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPRED.Stage-1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:36:41,245 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Launching Job 1 out of 1
2015-03-31 23:36:41,247 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-1:MAPRED] in serial mode
2015-03-31 23:36:41,247 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getInputSummary from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:36:41,249 INFO  [main]: exec.Utilities (Utilities.java:getInputSummary(2562)) - Cache Content Summary for hdfs://k05n22:54310/user/hive/warehouse/reqddata length: 0 file count: 0 directory count: 1
2015-03-31 23:36:41,250 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getInputSummary start=1427859401247 end=1427859401250 duration=3 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:36:41,250 INFO  [main]: exec.Utilities (Utilities.java:estimateNumberOfReducers(3119)) - BytesPerReducer=256000000 maxReducers=1009 totalInputFileSize=0
2015-03-31 23:36:41,250 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Number of reduce tasks not specified. Estimated from input data size: 1
2015-03-31 23:36:41,251 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to change the average load for a reducer (in bytes):
2015-03-31 23:36:41,251 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set hive.exec.reducers.bytes.per.reducer=<number>
2015-03-31 23:36:41,251 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to limit the maximum number of reducers:
2015-03-31 23:36:41,252 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set hive.exec.reducers.max=<number>
2015-03-31 23:36:41,252 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to set a constant number of reducers:
2015-03-31 23:36:41,252 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set mapreduce.job.reduces=<number>
2015-03-31 23:36:41,253 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-41_151_7970500752250191731-1
2015-03-31 23:36:41,256 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(287)) - Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2015-03-31 23:36:41,256 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3265)) - Processing alias reqddata
2015-03-31 23:36:41,256 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3282)) - Adding input file hdfs://k05n22:54310/user/hive/warehouse/reqddata
2015-03-31 23:36:41,257 INFO  [main]: exec.Utilities (Utilities.java:isEmptyPath(2601)) - Content Summary hdfs://k05n22:54310/user/hive/warehouse/reqddatalength: 0 num files: 0 num directories: 1
2015-03-31 23:36:41,264 INFO  [main]: exec.Utilities (Utilities.java:createDummyFileForEmptyPartition(3365)) - Changed input file to hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-41_151_7970500752250191731-1/-mr-10003/0
2015-03-31 23:36:41,264 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-41_151_7970500752250191731-1
2015-03-31 23:36:41,270 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:36:41,271 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapWork via kryo
2015-03-31 23:36:41,289 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859401270 end=1427859401289 duration=19 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:36:41,293 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:36:41,294 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing ReduceWork via kryo
2015-03-31 23:36:41,311 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859401293 end=1427859401311 duration=18 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:36:41,348 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:36:41,353 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-41_151_7970500752250191731-1/-ext-10002
2015-03-31 23:36:41,390 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:36:41,412 WARN  [main]: mapreduce.JobSubmitter (JobSubmitter.java:copyAndConfigureFiles(150)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-03-31 23:36:41,591 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:36:41,596 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(387)) - CombineHiveInputSplit creating pool for hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-41_151_7970500752250191731-1/-mr-10003/0; using filter path hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-41_151_7970500752250191731-1/-mr-10003/0
2015-03-31 23:36:41,602 INFO  [main]: input.FileInputFormat (FileInputFormat.java:listStatus(281)) - Total input paths to process : 1
2015-03-31 23:36:41,603 INFO  [main]: input.CombineFileInputFormat (CombineFileInputFormat.java:createSplits(413)) - DEBUG: Terminated node allocation with : CompletedNodes: 0, size left: 0
2015-03-31 23:36:41,605 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(442)) - number of splits 1
2015-03-31 23:36:41,605 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getSplits start=1427859401591 end=1427859401605 duration=14 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:36:41,606 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(521)) - Number of all splits 1
2015-03-31 23:36:41,640 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(396)) - number of splits:1
2015-03-31 23:36:41,672 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:printTokens(479)) - Submitting tokens for job: job_1427859192785_0003
2015-03-31 23:36:41,697 INFO  [main]: impl.YarnClientImpl (YarnClientImpl.java:submitApplication(236)) - Submitted application application_1427859192785_0003
2015-03-31 23:36:41,702 INFO  [main]: mapreduce.Job (Job.java:submit(1289)) - The url to track the job: http://k05n22:8088/proxy/application_1427859192785_0003/
2015-03-31 23:36:41,703 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Starting Job = job_1427859192785_0003, Tracking URL = http://k05n22:8088/proxy/application_1427859192785_0003/
2015-03-31 23:36:41,703 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Kill Command = /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop job  -kill job_1427859192785_0003
2015-03-31 23:36:54,103 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2015-03-31 23:36:54,160 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2015-03-31 23:36:54,160 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:36:54,159 Stage-1 map = 0%,  reduce = 0%
2015-03-31 23:37:00,440 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:37:00,440 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.59 sec
2015-03-31 23:37:08,866 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:37:08,865 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.24 sec
2015-03-31 23:37:09,927 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - MapReduce Total cumulative CPU time: 4 seconds 240 msec
2015-03-31 23:37:09,964 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Ended Job = job_1427859192785_0003
2015-03-31 23:37:09,979 INFO  [main]: exec.FileSinkOperator (Utilities.java:mvFileToFinalPath(1805)) - Moving tmp dir: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-41_151_7970500752250191731-1/_tmp.-ext-10001 to: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-41_151_7970500752250191731-1/-ext-10001
2015-03-31 23:37:09,983 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MOVE.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:09,984 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:MOVE] in serial mode
2015-03-31 23:37:09,985 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Moving data to: hdfs://k05n22:54310/user/hive/warehouse/last from hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-41_151_7970500752250191731-1/-ext-10001
2015-03-31 23:37:09,989 INFO  [main]: metadata.Hive (Hive.java:renameFile(2359)) - Replacing src:hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-41_151_7970500752250191731-1/-ext-10001;dest: hdfs://k05n22:54310/user/hive/warehouse/last;Status:true
2015-03-31 23:37:09,989 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-3 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:09,989 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-3:DDL] in serial mode
2015-03-31 23:37:09,994 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: create_table: Table(tableName:last, dbName:default, owner:u2, createTime:1427859429, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:l_stock_date, type:string, comment:null), FieldSchema(name:l_month, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2015-03-31 23:37:09,994 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=create_table: Table(tableName:last, dbName:default, owner:u2, createTime:1427859429, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:l_stock_date, type:string, comment:null), FieldSchema(name:l_month, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2015-03-31 23:37:10,005 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for last
2015-03-31 23:37:10,005 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table last to 0
2015-03-31 23:37:10,034 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.STATS.Stage-2 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,035 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-2:STATS] in serial mode
2015-03-31 23:37:10,035 INFO  [main]: exec.StatsTask (StatsTask.java:execute(86)) - Executing stats task
2015-03-31 23:37:10,035 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=last
2015-03-31 23:37:10,036 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=last	
2015-03-31 23:37:10,073 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-36-41_151_7970500752250191731-1/-ext-10002
2015-03-31 23:37:10,079 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:connect(68)) - Read stats : {default.last/={}}
2015-03-31 23:37:10,080 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.last/	numRows	0
2015-03-31 23:37:10,080 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.last/	rawDataSize	0
2015-03-31 23:37:10,084 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: alter_table: db=default tbl=last newtbl=last
2015-03-31 23:37:10,084 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=last newtbl=last	
2015-03-31 23:37:10,137 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for last
2015-03-31 23:37:10,137 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table last to 0
2015-03-31 23:37:10,159 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Table default.last stats: [numFiles=1, numRows=0, totalSize=0, rawDataSize=0]
2015-03-31 23:37:10,161 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859401244 end=1427859430161 duration=28917 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,162 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859401242 end=1427859430162 duration=28920 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,162 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - MapReduce Jobs Launched: 
2015-03-31 23:37:10,163 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.24 sec   HDFS Read: 296 HDFS Write: 38 SUCCESS
2015-03-31 23:37:10,163 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total MapReduce CPU Time Spent: 4 seconds 240 msec
2015-03-31 23:37:10,163 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:37:10,163 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,164 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859430163 end=1427859430164 duration=1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,164 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859401150 end=1427859430164 duration=29014 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,166 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 29.014 seconds
2015-03-31 23:37:10,167 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,167 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,167 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:37:10,167 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,169 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,169 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 

drop table mapbegin
2015-03-31 23:37:10,170 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:37:10,170 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859430169 end=1427859430170 duration=1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,170 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,171 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=mapbegin
2015-03-31 23:37:10,171 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mapbegin	
2015-03-31 23:37:10,174 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:37:10,174 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859430170 end=1427859430174 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,174 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:37:10,175 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859430167 end=1427859430174 duration=7 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,175 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,175 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 

drop table mapbegin
2015-03-31 23:37:10,175 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859430167 end=1427859430175 duration=8 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,176 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,176 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,176 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:37:10,177 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=mapbegin
2015-03-31 23:37:10,178 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mapbegin	
2015-03-31 23:37:10,180 ERROR [main]: metadata.Hive (Hive.java:getTable(1063)) - Table mapbegin not found: default.mapbegin table not found
2015-03-31 23:37:10,180 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=mapbegin
2015-03-31 23:37:10,180 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mapbegin	
2015-03-31 23:37:10,183 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859430176 end=1427859430182 duration=6 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,183 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859430175 end=1427859430183 duration=8 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,183 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:37:10,183 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,184 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859430183 end=1427859430184 duration=1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,184 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859430167 end=1427859430184 duration=17 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,184 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.017 seconds
2015-03-31 23:37:10,185 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,185 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,185 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:37:10,186 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,187 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,187 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 
create table mapbegin as
SELECT
B.stock_name, B.month, A.Adj_close AS adj
FROM
reqddata AS A,begin AS B
WHERE
A.stock_date = B.stock_date AND A.stock_name = B.stock_name
2015-03-31 23:37:10,197 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:37:10,198 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859430187 end=1427859430198 duration=11 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,198 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,199 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:37:10,199 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeCreateTable(10828)) - Creating table default.mapbegin position=13
2015-03-31 23:37:10,199 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:37:10,200 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:37:10,203 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=mapbegin
2015-03-31 23:37:10,203 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mapbegin	
2015-03-31 23:37:10,209 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10000)) - Completed phase 1 of Semantic Analysis
2015-03-31 23:37:10,209 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1554)) - Get metadata for source tables
2015-03-31 23:37:10,209 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=begin
2015-03-31 23:37:10,210 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=begin	
2015-03-31 23:37:10,236 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:37:10,236 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:37:10,262 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1702)) - Get metadata for subqueries
2015-03-31 23:37:10,263 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1726)) - Get metadata for destination tables
2015-03-31 23:37:10,263 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:37:10,264 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:37:10,270 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10003)) - Completed getting MetaData in Semantic Analysis
2015-03-31 23:37:10,363 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:genFileSinkPlan(6412)) - Set stats collection dir : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-ext-10002
2015-03-31 23:37:10,378 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for FS(9)
2015-03-31 23:37:10,378 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(8)
2015-03-31 23:37:10,379 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(410)) - Processing for FIL(7)
2015-03-31 23:37:10,389 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(465)) - Processing for JOIN(6)
2015-03-31 23:37:10,390 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for RS(5)
2015-03-31 23:37:10,391 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(410)) - Processing for FIL(4)
2015-03-31 23:37:10,392 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of FIL For Alias : b
2015-03-31 23:37:10,392 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_date is not null
2015-03-31 23:37:10,393 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_name is not null
2015-03-31 23:37:10,393 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(0)
2015-03-31 23:37:10,394 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of TS For Alias : b
2015-03-31 23:37:10,394 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_date is not null
2015-03-31 23:37:10,394 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_name is not null
2015-03-31 23:37:10,395 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for RS(3)
2015-03-31 23:37:10,396 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(410)) - Processing for FIL(2)
2015-03-31 23:37:10,397 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of FIL For Alias : a
2015-03-31 23:37:10,397 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_date is not null
2015-03-31 23:37:10,397 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_name is not null
2015-03-31 23:37:10,398 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(1)
2015-03-31 23:37:10,398 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of TS For Alias : a
2015-03-31 23:37:10,399 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_date is not null
2015-03-31 23:37:10,399 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_name is not null
2015-03-31 23:37:10,411 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:37:10,412 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427859430411 end=1427859430412 duration=1 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:37:10,412 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:37:10,413 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427859430412 end=1427859430413 duration=1 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:37:10,414 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneJoinOperator(921)) - JOIN 6 oldExprs: {0=[Column[KEY.reducesinkkey1], Column[KEY.reducesinkkey0], Column[VALUE._col0], Column[VALUE._col1], Column[VALUE._col2], Column[VALUE._col3], Column[VALUE._col4]], 1=[Column[KEY.reducesinkkey1], Column[KEY.reducesinkkey0], Column[VALUE._col0], Column[VALUE._col1], Column[VALUE._col2], Column[VALUE._col3]]}
2015-03-31 23:37:10,415 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneJoinOperator(1029)) - JOIN 6 newExprs: {0=[Column[KEY.reducesinkkey1], Column[KEY.reducesinkkey0], Column[VALUE._col1]], 1=[Column[KEY.reducesinkkey1], Column[KEY.reducesinkkey0], Column[VALUE._col0]]}
2015-03-31 23:37:10,415 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(761)) - RS 3 oldColExprMap: {VALUE._col4=Column[ROW__ID], VALUE._col3=Column[INPUT__FILE__NAME], VALUE._col2=Column[BLOCK__OFFSET__INSIDE__FILE], VALUE._col1=Column[adj_close], KEY.reducesinkkey1=Column[stock_name], VALUE._col0=Column[month], KEY.reducesinkkey0=Column[stock_date]}
2015-03-31 23:37:10,416 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(812)) - RS 3 newColExprMap: {VALUE._col1=Column[adj_close], KEY.reducesinkkey1=Column[stock_name], KEY.reducesinkkey0=Column[stock_date]}
2015-03-31 23:37:10,416 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(761)) - RS 5 oldColExprMap: {VALUE._col3=Column[ROW__ID], VALUE._col2=Column[INPUT__FILE__NAME], VALUE._col1=Column[BLOCK__OFFSET__INSIDE__FILE], KEY.reducesinkkey1=Column[stock_name], VALUE._col0=Column[month], KEY.reducesinkkey0=Column[stock_date]}
2015-03-31 23:37:10,417 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(812)) - RS 5 newColExprMap: {KEY.reducesinkkey1=Column[stock_name], VALUE._col0=Column[month], KEY.reducesinkkey0=Column[stock_date]}
2015-03-31 23:37:10,420 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:37:10,421 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:37:10,424 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:37:10,425 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:37:10,431 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getInputSummary from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:10,435 INFO  [main]: exec.Utilities (Utilities.java:getInputSummary(2562)) - Cache Content Summary for hdfs://k05n22:54310/user/hive/warehouse/begin length: 0 file count: 1 directory count: 1
2015-03-31 23:37:10,435 INFO  [main]: exec.Utilities (Utilities.java:getInputSummary(2562)) - Cache Content Summary for hdfs://k05n22:54310/user/hive/warehouse/reqddata length: 0 file count: 0 directory count: 1
2015-03-31 23:37:10,436 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getInputSummary start=1427859430431 end=1427859430435 duration=4 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:10,461 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1
2015-03-31 23:37:10,472 INFO  [main]: physical.LocalMapJoinProcFactory (LocalMapJoinProcFactory.java:process(139)) - Setting max memory usage to 0.9 for table sink not followed by group by
2015-03-31 23:37:10,486 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:37:10,486 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:37:10,487 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:37:10,487 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:37:10,488 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:37:10,488 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:37:10,490 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10173)) - Completed plan generation
2015-03-31 23:37:10,490 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:37:10,490 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859430198 end=1427859430490 duration=292 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,491 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:b.stock_name, type:string, comment:null), FieldSchema(name:b.month, type:string, comment:null), FieldSchema(name:adj, type:float, comment:null)], properties:null)
2015-03-31 23:37:10,491 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859430186 end=1427859430491 duration=305 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,491 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,491 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 
create table mapbegin as
SELECT
B.stock_name, B.month, A.Adj_close AS adj
FROM
reqddata AS A,begin AS B
WHERE
A.stock_date = B.stock_date AND A.stock_name = B.stock_name
2015-03-31 23:37:10,492 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Query ID = u2_20150331233737_7db2a66f-a3a6-44fd-87fd-c0ad5b3da213
2015-03-31 23:37:10,492 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total jobs = 1
2015-03-31 23:37:10,493 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859430185 end=1427859430492 duration=307 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,493 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,493 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPREDLOCAL.Stage-5 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:10,501 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-5:MAPREDLOCAL] in serial mode
2015-03-31 23:37:10,502 INFO  [main]: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(156)) - Generating plan file file:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-local-10005/plan.xml
2015-03-31 23:37:10,531 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:10,532 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapredLocalWork via kryo
2015-03-31 23:37:10,561 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859430531 end=1427859430561 duration=30 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:10,774 INFO  [main]: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(286)) - Executing: /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop jar /gpfs/util/academic/hive/apache-hive-0.14.0-bin/lib/hive-exec-0.14.0.jar org.apache.hadoop.hive.ql.exec.mr.ExecDriver -localtask -plan file:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-local-10005/plan.xml   -jobconffile file:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-local-10006/jobconf.xml
2015-03-31 23:37:16,716 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Execution completed successfully
2015-03-31 23:37:16,716 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - MapredLocal task succeeded
2015-03-31 23:37:16,717 INFO  [main]: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(311)) - Execution completed successfully
2015-03-31 23:37:16,717 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPRED.Stage-4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:16,718 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Launching Job 1 out of 1
2015-03-31 23:37:16,720 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-4:MAPRED] in serial mode
2015-03-31 23:37:16,720 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Number of reduce tasks is set to 0 since there's no reduce operator
2015-03-31 23:37:16,721 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1
2015-03-31 23:37:16,724 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(287)) - Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2015-03-31 23:37:16,752 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(355)) - Archive 1 hash table files to file:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-local-10003/HashTable-Stage-4/Stage-4.tar.gz
2015-03-31 23:37:16,768 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(362)) - Upload 1 archive file  fromfile:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-local-10003/HashTable-Stage-4/Stage-4.tar.gz to: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-mr-10004/HashTable-Stage-4/Stage-4.tar.gz
2015-03-31 23:37:16,768 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(367)) - Add 1 archive file to distributed cache. Archive file: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-mr-10004/HashTable-Stage-4/Stage-4.tar.gz
2015-03-31 23:37:16,769 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3265)) - Processing alias b
2015-03-31 23:37:16,769 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3282)) - Adding input file hdfs://k05n22:54310/user/hive/warehouse/begin
2015-03-31 23:37:16,769 INFO  [main]: exec.Utilities (Utilities.java:isEmptyPath(2601)) - Content Summary hdfs://k05n22:54310/user/hive/warehouse/beginlength: 0 num files: 1 num directories: 1
2015-03-31 23:37:16,770 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1
2015-03-31 23:37:16,775 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:16,775 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapWork via kryo
2015-03-31 23:37:16,809 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859436775 end=1427859436809 duration=34 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:16,847 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:37:16,851 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-ext-10002
2015-03-31 23:37:16,887 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:37:16,891 INFO  [main]: exec.Utilities (Utilities.java:getBaseWork(419)) - No plan file found: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-mr-10008/525ffb4b-2121-4895-a885-9d3890c8b071/reduce.xml
2015-03-31 23:37:16,903 WARN  [main]: mapreduce.JobSubmitter (JobSubmitter.java:copyAndConfigureFiles(150)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-03-31 23:37:17,051 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:37:17,055 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(387)) - CombineHiveInputSplit creating pool for hdfs://k05n22:54310/user/hive/warehouse/begin; using filter path hdfs://k05n22:54310/user/hive/warehouse/begin
2015-03-31 23:37:17,060 INFO  [main]: input.FileInputFormat (FileInputFormat.java:listStatus(281)) - Total input paths to process : 1
2015-03-31 23:37:17,061 INFO  [main]: input.CombineFileInputFormat (CombineFileInputFormat.java:createSplits(413)) - DEBUG: Terminated node allocation with : CompletedNodes: 0, size left: 0
2015-03-31 23:37:17,063 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(442)) - number of splits 1
2015-03-31 23:37:17,063 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getSplits start=1427859437051 end=1427859437063 duration=12 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:37:17,063 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(521)) - Number of all splits 1
2015-03-31 23:37:17,088 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(396)) - number of splits:1
2015-03-31 23:37:17,117 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:printTokens(479)) - Submitting tokens for job: job_1427859192785_0004
2015-03-31 23:37:17,142 INFO  [main]: impl.YarnClientImpl (YarnClientImpl.java:submitApplication(236)) - Submitted application application_1427859192785_0004
2015-03-31 23:37:17,147 INFO  [main]: mapreduce.Job (Job.java:submit(1289)) - The url to track the job: http://k05n22:8088/proxy/application_1427859192785_0004/
2015-03-31 23:37:17,147 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Starting Job = job_1427859192785_0004, Tracking URL = http://k05n22:8088/proxy/application_1427859192785_0004/
2015-03-31 23:37:17,148 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Kill Command = /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop job  -kill job_1427859192785_0004
2015-03-31 23:37:24,624 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 0
2015-03-31 23:37:24,678 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2015-03-31 23:37:24,678 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:37:24,677 Stage-4 map = 0%,  reduce = 0%
2015-03-31 23:37:32,046 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:37:32,046 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 2.1 sec
2015-03-31 23:37:33,103 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - MapReduce Total cumulative CPU time: 2 seconds 100 msec
2015-03-31 23:37:33,137 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Ended Job = job_1427859192785_0004
2015-03-31 23:37:33,149 INFO  [main]: exec.FileSinkOperator (Utilities.java:mvFileToFinalPath(1805)) - Moving tmp dir: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/_tmp.-ext-10001 to: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-ext-10001
2015-03-31 23:37:33,154 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MOVE.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,155 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:MOVE] in serial mode
2015-03-31 23:37:33,155 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Moving data to: hdfs://k05n22:54310/user/hive/warehouse/mapbegin from hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-ext-10001
2015-03-31 23:37:33,159 INFO  [main]: metadata.Hive (Hive.java:renameFile(2359)) - Replacing src:hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-ext-10001;dest: hdfs://k05n22:54310/user/hive/warehouse/mapbegin;Status:true
2015-03-31 23:37:33,159 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-6 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,160 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-6:DDL] in serial mode
2015-03-31 23:37:33,164 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: create_table: Table(tableName:mapbegin, dbName:default, owner:u2, createTime:1427859453, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:month, type:string, comment:null), FieldSchema(name:adj, type:float, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2015-03-31 23:37:33,164 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mapbegin, dbName:default, owner:u2, createTime:1427859453, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:month, type:string, comment:null), FieldSchema(name:adj, type:float, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2015-03-31 23:37:33,175 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for mapbegin
2015-03-31 23:37:33,176 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table mapbegin to 0
2015-03-31 23:37:33,203 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.STATS.Stage-2 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,203 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-2:STATS] in serial mode
2015-03-31 23:37:33,203 INFO  [main]: exec.StatsTask (StatsTask.java:execute(86)) - Executing stats task
2015-03-31 23:37:33,204 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=mapbegin
2015-03-31 23:37:33,204 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mapbegin	
2015-03-31 23:37:33,233 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-10_186_1456798394335723509-1/-ext-10002
2015-03-31 23:37:33,239 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:connect(68)) - Read stats : {default.mapbegin/={}}
2015-03-31 23:37:33,240 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.mapbegin/	numRows	0
2015-03-31 23:37:33,240 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.mapbegin/	rawDataSize	0
2015-03-31 23:37:33,244 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: alter_table: db=default tbl=mapbegin newtbl=mapbegin
2015-03-31 23:37:33,244 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=mapbegin newtbl=mapbegin	
2015-03-31 23:37:33,297 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for mapbegin
2015-03-31 23:37:33,297 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table mapbegin to 0
2015-03-31 23:37:33,318 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Table default.mapbegin stats: [numFiles=1, numRows=0, totalSize=0, rawDataSize=0]
2015-03-31 23:37:33,321 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859430493 end=1427859453321 duration=22828 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,321 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859430491 end=1427859453321 duration=22830 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,321 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - MapReduce Jobs Launched: 
2015-03-31 23:37:33,322 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Stage-Stage-4: Map: 1   Cumulative CPU: 2.1 sec   HDFS Read: 208 HDFS Write: 42 SUCCESS
2015-03-31 23:37:33,322 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total MapReduce CPU Time Spent: 2 seconds 100 msec
2015-03-31 23:37:33,323 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:37:33,323 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,323 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859453323 end=1427859453323 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,323 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859430185 end=1427859453323 duration=23138 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,328 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 23.139 seconds
2015-03-31 23:37:33,328 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,329 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,329 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:37:33,329 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,330 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,331 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 


drop table mapend
2015-03-31 23:37:33,331 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:37:33,332 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859453330 end=1427859453332 duration=2 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,332 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,333 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=mapend
2015-03-31 23:37:33,333 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mapend	
2015-03-31 23:37:33,335 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:37:33,336 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859453332 end=1427859453336 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,336 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:37:33,336 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859453329 end=1427859453336 duration=7 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,337 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,337 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 


drop table mapend
2015-03-31 23:37:33,337 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859453329 end=1427859453337 duration=8 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,337 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,338 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,338 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:37:33,339 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=mapend
2015-03-31 23:37:33,339 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mapend	
2015-03-31 23:37:33,341 ERROR [main]: metadata.Hive (Hive.java:getTable(1063)) - Table mapend not found: default.mapend table not found
2015-03-31 23:37:33,342 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=mapend
2015-03-31 23:37:33,342 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mapend	
2015-03-31 23:37:33,344 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859453337 end=1427859453344 duration=7 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,345 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859453337 end=1427859453345 duration=8 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,345 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:37:33,345 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,345 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859453345 end=1427859453345 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,346 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859453328 end=1427859453346 duration=18 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,346 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.018 seconds
2015-03-31 23:37:33,347 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,347 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,347 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:37:33,347 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,348 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,349 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 
create table mapend as
SELECT
B.stock_name, B.l_month, A.Adj_close AS adj
FROM
reqddata AS A,last AS B
WHERE
A.stock_date = B.l_stock_date AND A.stock_name = B.stock_name
2015-03-31 23:37:33,353 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:37:33,353 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859453348 end=1427859453353 duration=5 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,354 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,354 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:37:33,355 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeCreateTable(10828)) - Creating table default.mapend position=13
2015-03-31 23:37:33,355 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:37:33,355 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:37:33,359 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=mapend
2015-03-31 23:37:33,359 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mapend	
2015-03-31 23:37:33,361 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10000)) - Completed phase 1 of Semantic Analysis
2015-03-31 23:37:33,361 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1554)) - Get metadata for source tables
2015-03-31 23:37:33,362 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=last
2015-03-31 23:37:33,362 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=last	
2015-03-31 23:37:33,388 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=reqddata
2015-03-31 23:37:33,389 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=reqddata	
2015-03-31 23:37:33,415 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1702)) - Get metadata for subqueries
2015-03-31 23:37:33,415 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1726)) - Get metadata for destination tables
2015-03-31 23:37:33,416 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:37:33,417 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:37:33,423 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10003)) - Completed getting MetaData in Semantic Analysis
2015-03-31 23:37:33,437 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:genFileSinkPlan(6412)) - Set stats collection dir : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-ext-10002
2015-03-31 23:37:33,447 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for FS(9)
2015-03-31 23:37:33,448 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(8)
2015-03-31 23:37:33,448 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(410)) - Processing for FIL(7)
2015-03-31 23:37:33,449 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(465)) - Processing for JOIN(6)
2015-03-31 23:37:33,450 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for RS(5)
2015-03-31 23:37:33,450 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(410)) - Processing for FIL(4)
2015-03-31 23:37:33,451 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of FIL For Alias : b
2015-03-31 23:37:33,452 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	l_stock_date is not null
2015-03-31 23:37:33,452 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_name is not null
2015-03-31 23:37:33,452 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(0)
2015-03-31 23:37:33,453 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of TS For Alias : b
2015-03-31 23:37:33,453 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	l_stock_date is not null
2015-03-31 23:37:33,454 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_name is not null
2015-03-31 23:37:33,454 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for RS(3)
2015-03-31 23:37:33,455 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(410)) - Processing for FIL(2)
2015-03-31 23:37:33,456 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of FIL For Alias : a
2015-03-31 23:37:33,456 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_date is not null
2015-03-31 23:37:33,456 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_name is not null
2015-03-31 23:37:33,457 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(1)
2015-03-31 23:37:33,457 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of TS For Alias : a
2015-03-31 23:37:33,458 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_date is not null
2015-03-31 23:37:33,458 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_name is not null
2015-03-31 23:37:33,462 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:37:33,463 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427859453462 end=1427859453463 duration=1 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:37:33,463 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:37:33,463 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427859453463 end=1427859453463 duration=0 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:37:33,465 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneJoinOperator(921)) - JOIN 6 oldExprs: {0=[Column[KEY.reducesinkkey1], Column[KEY.reducesinkkey0], Column[VALUE._col0], Column[VALUE._col1], Column[VALUE._col2], Column[VALUE._col3], Column[VALUE._col4]], 1=[Column[KEY.reducesinkkey1], Column[KEY.reducesinkkey0], Column[VALUE._col0], Column[VALUE._col1], Column[VALUE._col2], Column[VALUE._col3]]}
2015-03-31 23:37:33,465 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneJoinOperator(1029)) - JOIN 6 newExprs: {0=[Column[KEY.reducesinkkey1], Column[KEY.reducesinkkey0], Column[VALUE._col1]], 1=[Column[KEY.reducesinkkey1], Column[KEY.reducesinkkey0], Column[VALUE._col0]]}
2015-03-31 23:37:33,466 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(761)) - RS 3 oldColExprMap: {VALUE._col4=Column[ROW__ID], VALUE._col3=Column[INPUT__FILE__NAME], VALUE._col2=Column[BLOCK__OFFSET__INSIDE__FILE], VALUE._col1=Column[adj_close], KEY.reducesinkkey1=Column[stock_name], VALUE._col0=Column[month], KEY.reducesinkkey0=Column[stock_date]}
2015-03-31 23:37:33,466 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(812)) - RS 3 newColExprMap: {VALUE._col1=Column[adj_close], KEY.reducesinkkey1=Column[stock_name], KEY.reducesinkkey0=Column[stock_date]}
2015-03-31 23:37:33,466 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(761)) - RS 5 oldColExprMap: {VALUE._col3=Column[ROW__ID], VALUE._col2=Column[INPUT__FILE__NAME], VALUE._col1=Column[BLOCK__OFFSET__INSIDE__FILE], KEY.reducesinkkey1=Column[stock_name], VALUE._col0=Column[l_month], KEY.reducesinkkey0=Column[l_stock_date]}
2015-03-31 23:37:33,467 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(812)) - RS 5 newColExprMap: {KEY.reducesinkkey1=Column[stock_name], VALUE._col0=Column[l_month], KEY.reducesinkkey0=Column[l_stock_date]}
2015-03-31 23:37:33,470 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:37:33,471 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:37:33,474 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:37:33,474 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:37:33,480 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getInputSummary from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:33,484 INFO  [main]: exec.Utilities (Utilities.java:getInputSummary(2562)) - Cache Content Summary for hdfs://k05n22:54310/user/hive/warehouse/last length: 0 file count: 1 directory count: 1
2015-03-31 23:37:33,484 INFO  [main]: exec.Utilities (Utilities.java:getInputSummary(2562)) - Cache Content Summary for hdfs://k05n22:54310/user/hive/warehouse/reqddata length: 0 file count: 0 directory count: 1
2015-03-31 23:37:33,484 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getInputSummary start=1427859453480 end=1427859453484 duration=4 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:33,508 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1
2015-03-31 23:37:33,510 INFO  [main]: physical.LocalMapJoinProcFactory (LocalMapJoinProcFactory.java:process(139)) - Setting max memory usage to 0.9 for table sink not followed by group by
2015-03-31 23:37:33,511 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:37:33,512 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:37:33,512 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:37:33,513 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:37:33,513 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:37:33,514 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:37:33,515 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10173)) - Completed plan generation
2015-03-31 23:37:33,515 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:37:33,515 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859453354 end=1427859453515 duration=161 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,516 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:b.stock_name, type:string, comment:null), FieldSchema(name:b.l_month, type:string, comment:null), FieldSchema(name:adj, type:float, comment:null)], properties:null)
2015-03-31 23:37:33,516 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859453347 end=1427859453516 duration=169 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,516 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,517 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 
create table mapend as
SELECT
B.stock_name, B.l_month, A.Adj_close AS adj
FROM
reqddata AS A,last AS B
WHERE
A.stock_date = B.l_stock_date AND A.stock_name = B.stock_name
2015-03-31 23:37:33,517 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Query ID = u2_20150331233737_977dd006-2fe5-4cf4-84fb-a02c018726bd
2015-03-31 23:37:33,517 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total jobs = 1
2015-03-31 23:37:33,518 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859453347 end=1427859453518 duration=171 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,518 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,518 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPREDLOCAL.Stage-5 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:33,521 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-5:MAPREDLOCAL] in serial mode
2015-03-31 23:37:33,521 INFO  [main]: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(156)) - Generating plan file file:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-local-10005/plan.xml
2015-03-31 23:37:33,543 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:33,544 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapredLocalWork via kryo
2015-03-31 23:37:33,548 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859453543 end=1427859453548 duration=5 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:33,710 INFO  [main]: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(286)) - Executing: /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop jar /gpfs/util/academic/hive/apache-hive-0.14.0-bin/lib/hive-exec-0.14.0.jar org.apache.hadoop.hive.ql.exec.mr.ExecDriver -localtask -plan file:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-local-10005/plan.xml   -jobconffile file:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-local-10006/jobconf.xml
2015-03-31 23:37:38,998 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Execution completed successfully
2015-03-31 23:37:38,998 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - MapredLocal task succeeded
2015-03-31 23:37:38,999 INFO  [main]: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(311)) - Execution completed successfully
2015-03-31 23:37:38,999 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPRED.Stage-4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:39,000 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Launching Job 1 out of 1
2015-03-31 23:37:39,002 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-4:MAPRED] in serial mode
2015-03-31 23:37:39,002 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Number of reduce tasks is set to 0 since there's no reduce operator
2015-03-31 23:37:39,003 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1
2015-03-31 23:37:39,006 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(287)) - Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2015-03-31 23:37:39,008 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(355)) - Archive 1 hash table files to file:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-local-10003/HashTable-Stage-4/Stage-4.tar.gz
2015-03-31 23:37:39,027 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(362)) - Upload 1 archive file  fromfile:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-local-10003/HashTable-Stage-4/Stage-4.tar.gz to: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-mr-10004/HashTable-Stage-4/Stage-4.tar.gz
2015-03-31 23:37:39,027 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(367)) - Add 1 archive file to distributed cache. Archive file: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-mr-10004/HashTable-Stage-4/Stage-4.tar.gz
2015-03-31 23:37:39,027 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3265)) - Processing alias b
2015-03-31 23:37:39,028 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3282)) - Adding input file hdfs://k05n22:54310/user/hive/warehouse/last
2015-03-31 23:37:39,028 INFO  [main]: exec.Utilities (Utilities.java:isEmptyPath(2601)) - Content Summary hdfs://k05n22:54310/user/hive/warehouse/lastlength: 0 num files: 1 num directories: 1
2015-03-31 23:37:39,029 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1
2015-03-31 23:37:39,033 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:39,034 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapWork via kryo
2015-03-31 23:37:39,052 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859459033 end=1427859459052 duration=19 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:39,084 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:37:39,088 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-ext-10002
2015-03-31 23:37:39,119 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:37:39,122 INFO  [main]: exec.Utilities (Utilities.java:getBaseWork(419)) - No plan file found: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-mr-10008/a56f0f45-cec3-4dab-bafe-48081f3661a7/reduce.xml
2015-03-31 23:37:39,136 WARN  [main]: mapreduce.JobSubmitter (JobSubmitter.java:copyAndConfigureFiles(150)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-03-31 23:37:39,310 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:37:39,314 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(387)) - CombineHiveInputSplit creating pool for hdfs://k05n22:54310/user/hive/warehouse/last; using filter path hdfs://k05n22:54310/user/hive/warehouse/last
2015-03-31 23:37:39,319 INFO  [main]: input.FileInputFormat (FileInputFormat.java:listStatus(281)) - Total input paths to process : 1
2015-03-31 23:37:39,320 INFO  [main]: input.CombineFileInputFormat (CombineFileInputFormat.java:createSplits(413)) - DEBUG: Terminated node allocation with : CompletedNodes: 0, size left: 0
2015-03-31 23:37:39,322 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(442)) - number of splits 1
2015-03-31 23:37:39,323 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getSplits start=1427859459310 end=1427859459323 duration=13 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:37:39,323 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(521)) - Number of all splits 1
2015-03-31 23:37:39,348 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(396)) - number of splits:1
2015-03-31 23:37:39,375 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:printTokens(479)) - Submitting tokens for job: job_1427859192785_0005
2015-03-31 23:37:39,399 INFO  [main]: impl.YarnClientImpl (YarnClientImpl.java:submitApplication(236)) - Submitted application application_1427859192785_0005
2015-03-31 23:37:39,404 INFO  [main]: mapreduce.Job (Job.java:submit(1289)) - The url to track the job: http://k05n22:8088/proxy/application_1427859192785_0005/
2015-03-31 23:37:39,404 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Starting Job = job_1427859192785_0005, Tracking URL = http://k05n22:8088/proxy/application_1427859192785_0005/
2015-03-31 23:37:39,405 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Kill Command = /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop job  -kill job_1427859192785_0005
2015-03-31 23:37:46,643 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 0
2015-03-31 23:37:46,671 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2015-03-31 23:37:46,672 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:37:46,671 Stage-4 map = 0%,  reduce = 0%
2015-03-31 23:37:54,008 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:37:54,008 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 2.03 sec
2015-03-31 23:37:55,064 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - MapReduce Total cumulative CPU time: 2 seconds 30 msec
2015-03-31 23:37:55,097 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Ended Job = job_1427859192785_0005
2015-03-31 23:37:55,110 INFO  [main]: exec.FileSinkOperator (Utilities.java:mvFileToFinalPath(1805)) - Moving tmp dir: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/_tmp.-ext-10001 to: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-ext-10001
2015-03-31 23:37:55,115 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MOVE.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,116 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:MOVE] in serial mode
2015-03-31 23:37:55,116 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Moving data to: hdfs://k05n22:54310/user/hive/warehouse/mapend from hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-ext-10001
2015-03-31 23:37:55,120 INFO  [main]: metadata.Hive (Hive.java:renameFile(2359)) - Replacing src:hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-ext-10001;dest: hdfs://k05n22:54310/user/hive/warehouse/mapend;Status:true
2015-03-31 23:37:55,120 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-6 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,120 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-6:DDL] in serial mode
2015-03-31 23:37:55,124 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: create_table: Table(tableName:mapend, dbName:default, owner:u2, createTime:1427859475, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:l_month, type:string, comment:null), FieldSchema(name:adj, type:float, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2015-03-31 23:37:55,124 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=create_table: Table(tableName:mapend, dbName:default, owner:u2, createTime:1427859475, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:l_month, type:string, comment:null), FieldSchema(name:adj, type:float, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2015-03-31 23:37:55,136 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for mapend
2015-03-31 23:37:55,136 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table mapend to 0
2015-03-31 23:37:55,197 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.STATS.Stage-2 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,198 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-2:STATS] in serial mode
2015-03-31 23:37:55,198 INFO  [main]: exec.StatsTask (StatsTask.java:execute(86)) - Executing stats task
2015-03-31 23:37:55,198 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=mapend
2015-03-31 23:37:55,199 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mapend	
2015-03-31 23:37:55,228 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-33_348_5579653490028060006-1/-ext-10002
2015-03-31 23:37:55,235 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:connect(68)) - Read stats : {default.mapend/={}}
2015-03-31 23:37:55,235 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.mapend/	numRows	0
2015-03-31 23:37:55,236 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.mapend/	rawDataSize	0
2015-03-31 23:37:55,239 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: alter_table: db=default tbl=mapend newtbl=mapend
2015-03-31 23:37:55,240 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=mapend newtbl=mapend	
2015-03-31 23:37:55,292 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for mapend
2015-03-31 23:37:55,293 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table mapend to 0
2015-03-31 23:37:55,314 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Table default.mapend stats: [numFiles=1, numRows=0, totalSize=0, rawDataSize=0]
2015-03-31 23:37:55,316 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859453518 end=1427859475316 duration=21798 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,316 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859453516 end=1427859475316 duration=21800 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,317 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - MapReduce Jobs Launched: 
2015-03-31 23:37:55,317 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Stage-Stage-4: Map: 1   Cumulative CPU: 2.03 sec   HDFS Read: 207 HDFS Write: 40 SUCCESS
2015-03-31 23:37:55,317 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total MapReduce CPU Time Spent: 2 seconds 30 msec
2015-03-31 23:37:55,318 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:37:55,318 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,318 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859475318 end=1427859475318 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,319 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859453347 end=1427859475319 duration=21972 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,323 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 21.973 seconds
2015-03-31 23:37:55,323 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,323 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,324 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:37:55,324 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,325 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,325 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 

drop table XiVals
2015-03-31 23:37:55,326 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:37:55,327 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859475325 end=1427859475326 duration=1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,327 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,327 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=XiVals
2015-03-31 23:37:55,328 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=XiVals	
2015-03-31 23:37:55,330 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:37:55,330 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859475327 end=1427859475330 duration=3 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,331 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:37:55,331 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859475324 end=1427859475331 duration=7 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,331 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,332 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 

drop table XiVals
2015-03-31 23:37:55,332 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859475323 end=1427859475332 duration=9 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,332 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,332 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,333 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:37:55,333 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=XiVals
2015-03-31 23:37:55,334 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=XiVals	
2015-03-31 23:37:55,336 ERROR [main]: metadata.Hive (Hive.java:getTable(1063)) - Table XiVals not found: default.XiVals table not found
2015-03-31 23:37:55,336 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=XiVals
2015-03-31 23:37:55,337 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=XiVals	
2015-03-31 23:37:55,339 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859475332 end=1427859475339 duration=7 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,339 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859475331 end=1427859475339 duration=8 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,340 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:37:55,340 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,340 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859475340 end=1427859475340 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,340 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859475323 end=1427859475340 duration=17 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,341 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.018 seconds
2015-03-31 23:37:55,341 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,341 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,342 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:37:55,342 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,343 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,343 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 
create table XiVals as
SELECT
A.stock_name, A.l_month, (A.adj - B.adj)/B.adj AS difference
FROM
mapend AS A,mapbegin AS B
WHERE
A.stock_name = B.stock_name AND A.l_month = B.month
2015-03-31 23:37:55,351 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:37:55,352 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859475343 end=1427859475351 duration=8 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,352 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,352 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:37:55,353 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeCreateTable(10828)) - Creating table default.XiVals position=13
2015-03-31 23:37:55,353 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:37:55,354 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:37:55,357 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=XiVals
2015-03-31 23:37:55,357 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=XiVals	
2015-03-31 23:37:55,359 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10000)) - Completed phase 1 of Semantic Analysis
2015-03-31 23:37:55,360 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1554)) - Get metadata for source tables
2015-03-31 23:37:55,360 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=mapbegin
2015-03-31 23:37:55,360 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mapbegin	
2015-03-31 23:37:55,386 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=mapend
2015-03-31 23:37:55,386 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=mapend	
2015-03-31 23:37:55,411 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1702)) - Get metadata for subqueries
2015-03-31 23:37:55,411 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1726)) - Get metadata for destination tables
2015-03-31 23:37:55,412 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:37:55,412 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:37:55,419 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10003)) - Completed getting MetaData in Semantic Analysis
2015-03-31 23:37:55,438 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:genFileSinkPlan(6412)) - Set stats collection dir : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-ext-10002
2015-03-31 23:37:55,485 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for FS(9)
2015-03-31 23:37:55,485 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(8)
2015-03-31 23:37:55,486 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(410)) - Processing for FIL(7)
2015-03-31 23:37:55,487 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(465)) - Processing for JOIN(6)
2015-03-31 23:37:55,488 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for RS(5)
2015-03-31 23:37:55,488 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(410)) - Processing for FIL(4)
2015-03-31 23:37:55,489 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of FIL For Alias : b
2015-03-31 23:37:55,489 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_name is not null
2015-03-31 23:37:55,489 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	month is not null
2015-03-31 23:37:55,490 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(0)
2015-03-31 23:37:55,491 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of TS For Alias : b
2015-03-31 23:37:55,491 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_name is not null
2015-03-31 23:37:55,491 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	month is not null
2015-03-31 23:37:55,492 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for RS(3)
2015-03-31 23:37:55,492 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(410)) - Processing for FIL(2)
2015-03-31 23:37:55,493 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of FIL For Alias : a
2015-03-31 23:37:55,493 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_name is not null
2015-03-31 23:37:55,494 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	l_month is not null
2015-03-31 23:37:55,494 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(1)
2015-03-31 23:37:55,495 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of TS For Alias : a
2015-03-31 23:37:55,495 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	stock_name is not null
2015-03-31 23:37:55,495 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	l_month is not null
2015-03-31 23:37:55,499 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:37:55,499 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427859475499 end=1427859475499 duration=0 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:37:55,500 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:37:55,500 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427859475500 end=1427859475500 duration=0 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:37:55,502 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneJoinOperator(921)) - JOIN 6 oldExprs: {0=[Column[KEY.reducesinkkey0], Column[KEY.reducesinkkey1], Column[VALUE._col0], Column[VALUE._col1], Column[VALUE._col2], Column[VALUE._col3]], 1=[Column[KEY.reducesinkkey0], Column[KEY.reducesinkkey1], Column[VALUE._col0], Column[VALUE._col1], Column[VALUE._col2], Column[VALUE._col3]]}
2015-03-31 23:37:55,502 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneJoinOperator(1029)) - JOIN 6 newExprs: {0=[Column[KEY.reducesinkkey0], Column[KEY.reducesinkkey1], Column[VALUE._col0]], 1=[Column[KEY.reducesinkkey0], Column[KEY.reducesinkkey1], Column[VALUE._col0]]}
2015-03-31 23:37:55,503 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(761)) - RS 3 oldColExprMap: {VALUE._col3=Column[ROW__ID], VALUE._col2=Column[INPUT__FILE__NAME], VALUE._col1=Column[BLOCK__OFFSET__INSIDE__FILE], KEY.reducesinkkey1=Column[l_month], VALUE._col0=Column[adj], KEY.reducesinkkey0=Column[stock_name]}
2015-03-31 23:37:55,503 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(812)) - RS 3 newColExprMap: {KEY.reducesinkkey1=Column[l_month], VALUE._col0=Column[adj], KEY.reducesinkkey0=Column[stock_name]}
2015-03-31 23:37:55,503 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(761)) - RS 5 oldColExprMap: {VALUE._col3=Column[ROW__ID], VALUE._col2=Column[INPUT__FILE__NAME], VALUE._col1=Column[BLOCK__OFFSET__INSIDE__FILE], KEY.reducesinkkey1=Column[month], VALUE._col0=Column[adj], KEY.reducesinkkey0=Column[stock_name]}
2015-03-31 23:37:55,504 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(812)) - RS 5 newColExprMap: {KEY.reducesinkkey1=Column[month], VALUE._col0=Column[adj], KEY.reducesinkkey0=Column[stock_name]}
2015-03-31 23:37:55,511 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:37:55,511 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:37:55,515 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:37:55,515 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:37:55,521 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getInputSummary from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:55,525 INFO  [main]: exec.Utilities (Utilities.java:getInputSummary(2562)) - Cache Content Summary for hdfs://k05n22:54310/user/hive/warehouse/mapend length: 0 file count: 1 directory count: 1
2015-03-31 23:37:55,525 INFO  [main]: exec.Utilities (Utilities.java:getInputSummary(2562)) - Cache Content Summary for hdfs://k05n22:54310/user/hive/warehouse/mapbegin length: 0 file count: 1 directory count: 1
2015-03-31 23:37:55,526 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getInputSummary start=1427859475521 end=1427859475526 duration=5 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:55,548 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1
2015-03-31 23:37:55,549 INFO  [main]: physical.LocalMapJoinProcFactory (LocalMapJoinProcFactory.java:process(139)) - Setting max memory usage to 0.9 for table sink not followed by group by
2015-03-31 23:37:55,550 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:37:55,551 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:37:55,551 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:37:55,552 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:37:55,552 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:37:55,553 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:37:55,554 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10173)) - Completed plan generation
2015-03-31 23:37:55,554 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:37:55,554 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859475352 end=1427859475554 duration=202 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,555 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:a.stock_name, type:string, comment:null), FieldSchema(name:a.l_month, type:string, comment:null), FieldSchema(name:difference, type:double, comment:null)], properties:null)
2015-03-31 23:37:55,555 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859475342 end=1427859475555 duration=213 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,555 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,555 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 
create table XiVals as
SELECT
A.stock_name, A.l_month, (A.adj - B.adj)/B.adj AS difference
FROM
mapend AS A,mapbegin AS B
WHERE
A.stock_name = B.stock_name AND A.l_month = B.month
2015-03-31 23:37:55,556 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Query ID = u2_20150331233737_abb71412-f029-4346-b8cc-ad45ce60c37a
2015-03-31 23:37:55,556 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total jobs = 1
2015-03-31 23:37:55,557 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859475341 end=1427859475557 duration=216 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,557 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,557 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPREDLOCAL.Stage-5 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:37:55,559 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-5:MAPREDLOCAL] in serial mode
2015-03-31 23:37:55,560 INFO  [main]: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(156)) - Generating plan file file:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-local-10005/plan.xml
2015-03-31 23:37:55,577 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:55,577 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapredLocalWork via kryo
2015-03-31 23:37:55,582 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859475577 end=1427859475582 duration=5 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:37:55,732 INFO  [main]: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(286)) - Executing: /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop jar /gpfs/util/academic/hive/apache-hive-0.14.0-bin/lib/hive-exec-0.14.0.jar org.apache.hadoop.hive.ql.exec.mr.ExecDriver -localtask -plan file:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-local-10005/plan.xml   -jobconffile file:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-local-10006/jobconf.xml
2015-03-31 23:38:01,079 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Execution completed successfully
2015-03-31 23:38:01,080 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - MapredLocal task succeeded
2015-03-31 23:38:01,080 INFO  [main]: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(311)) - Execution completed successfully
2015-03-31 23:38:01,081 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPRED.Stage-4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:01,082 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Launching Job 1 out of 1
2015-03-31 23:38:01,084 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-4:MAPRED] in serial mode
2015-03-31 23:38:01,084 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Number of reduce tasks is set to 0 since there's no reduce operator
2015-03-31 23:38:01,085 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1
2015-03-31 23:38:01,089 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(287)) - Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2015-03-31 23:38:01,091 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(355)) - Archive 1 hash table files to file:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-local-10003/HashTable-Stage-4/Stage-4.tar.gz
2015-03-31 23:38:01,113 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(362)) - Upload 1 archive file  fromfile:/tmp/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-local-10003/HashTable-Stage-4/Stage-4.tar.gz to: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-mr-10004/HashTable-Stage-4/Stage-4.tar.gz
2015-03-31 23:38:01,113 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(367)) - Add 1 archive file to distributed cache. Archive file: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-mr-10004/HashTable-Stage-4/Stage-4.tar.gz
2015-03-31 23:38:01,114 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3265)) - Processing alias b
2015-03-31 23:38:01,114 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3282)) - Adding input file hdfs://k05n22:54310/user/hive/warehouse/mapbegin
2015-03-31 23:38:01,114 INFO  [main]: exec.Utilities (Utilities.java:isEmptyPath(2601)) - Content Summary hdfs://k05n22:54310/user/hive/warehouse/mapbeginlength: 0 num files: 1 num directories: 1
2015-03-31 23:38:01,115 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1
2015-03-31 23:38:01,120 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:38:01,120 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapWork via kryo
2015-03-31 23:38:01,148 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859481120 end=1427859481147 duration=27 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:38:01,185 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:38:01,190 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-ext-10002
2015-03-31 23:38:01,227 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:38:01,231 INFO  [main]: exec.Utilities (Utilities.java:getBaseWork(419)) - No plan file found: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-mr-10008/15977420-4541-419e-9608-9588280ee1c3/reduce.xml
2015-03-31 23:38:01,241 WARN  [main]: mapreduce.JobSubmitter (JobSubmitter.java:copyAndConfigureFiles(150)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-03-31 23:38:01,406 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:38:01,411 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(387)) - CombineHiveInputSplit creating pool for hdfs://k05n22:54310/user/hive/warehouse/mapbegin; using filter path hdfs://k05n22:54310/user/hive/warehouse/mapbegin
2015-03-31 23:38:01,416 INFO  [main]: input.FileInputFormat (FileInputFormat.java:listStatus(281)) - Total input paths to process : 1
2015-03-31 23:38:01,417 INFO  [main]: input.CombineFileInputFormat (CombineFileInputFormat.java:createSplits(413)) - DEBUG: Terminated node allocation with : CompletedNodes: 0, size left: 0
2015-03-31 23:38:01,418 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(442)) - number of splits 1
2015-03-31 23:38:01,419 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getSplits start=1427859481406 end=1427859481419 duration=13 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:38:01,419 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(521)) - Number of all splits 1
2015-03-31 23:38:01,444 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(396)) - number of splits:1
2015-03-31 23:38:01,480 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:printTokens(479)) - Submitting tokens for job: job_1427859192785_0006
2015-03-31 23:38:01,504 INFO  [main]: impl.YarnClientImpl (YarnClientImpl.java:submitApplication(236)) - Submitted application application_1427859192785_0006
2015-03-31 23:38:01,508 INFO  [main]: mapreduce.Job (Job.java:submit(1289)) - The url to track the job: http://k05n22:8088/proxy/application_1427859192785_0006/
2015-03-31 23:38:01,509 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Starting Job = job_1427859192785_0006, Tracking URL = http://k05n22:8088/proxy/application_1427859192785_0006/
2015-03-31 23:38:01,509 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Kill Command = /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop job  -kill job_1427859192785_0006
2015-03-31 23:38:08,908 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 0
2015-03-31 23:38:08,963 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2015-03-31 23:38:08,963 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:38:08,962 Stage-4 map = 0%,  reduce = 0%
2015-03-31 23:38:16,263 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:38:16,262 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 2.44 sec
2015-03-31 23:38:17,318 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - MapReduce Total cumulative CPU time: 2 seconds 440 msec
2015-03-31 23:38:17,351 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Ended Job = job_1427859192785_0006
2015-03-31 23:38:17,364 INFO  [main]: exec.FileSinkOperator (Utilities.java:mvFileToFinalPath(1805)) - Moving tmp dir: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/_tmp.-ext-10001 to: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-ext-10001
2015-03-31 23:38:17,369 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MOVE.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,369 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:MOVE] in serial mode
2015-03-31 23:38:17,370 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Moving data to: hdfs://k05n22:54310/user/hive/warehouse/xivals from hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-ext-10001
2015-03-31 23:38:17,373 INFO  [main]: metadata.Hive (Hive.java:renameFile(2359)) - Replacing src:hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-ext-10001;dest: hdfs://k05n22:54310/user/hive/warehouse/xivals;Status:true
2015-03-31 23:38:17,374 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-6 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,374 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-6:DDL] in serial mode
2015-03-31 23:38:17,377 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: create_table: Table(tableName:XiVals, dbName:default, owner:u2, createTime:1427859497, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:l_month, type:string, comment:null), FieldSchema(name:difference, type:double, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2015-03-31 23:38:17,378 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=create_table: Table(tableName:XiVals, dbName:default, owner:u2, createTime:1427859497, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:l_month, type:string, comment:null), FieldSchema(name:difference, type:double, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2015-03-31 23:38:17,390 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for XiVals
2015-03-31 23:38:17,390 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table XiVals to 0
2015-03-31 23:38:17,417 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.STATS.Stage-2 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,417 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-2:STATS] in serial mode
2015-03-31 23:38:17,418 INFO  [main]: exec.StatsTask (StatsTask.java:execute(86)) - Executing stats task
2015-03-31 23:38:17,418 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=XiVals
2015-03-31 23:38:17,418 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=XiVals	
2015-03-31 23:38:17,445 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-37-55_343_6188560879017934263-1/-ext-10002
2015-03-31 23:38:17,453 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:connect(68)) - Read stats : {default.XiVals/={}}
2015-03-31 23:38:17,453 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.xivals/	numRows	0
2015-03-31 23:38:17,453 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.xivals/	rawDataSize	0
2015-03-31 23:38:17,457 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: alter_table: db=default tbl=xivals newtbl=xivals
2015-03-31 23:38:17,458 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=xivals newtbl=xivals	
2015-03-31 23:38:17,511 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for xivals
2015-03-31 23:38:17,511 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table xivals to 0
2015-03-31 23:38:17,532 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Table default.xivals stats: [numFiles=1, numRows=0, totalSize=0, rawDataSize=0]
2015-03-31 23:38:17,534 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859475557 end=1427859497534 duration=21977 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,534 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859475555 end=1427859497534 duration=21979 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,534 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - MapReduce Jobs Launched: 
2015-03-31 23:38:17,535 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Stage-Stage-4: Map: 1   Cumulative CPU: 2.44 sec   HDFS Read: 211 HDFS Write: 40 SUCCESS
2015-03-31 23:38:17,535 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total MapReduce CPU Time Spent: 2 seconds 440 msec
2015-03-31 23:38:17,536 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:38:17,536 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,536 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859497536 end=1427859497536 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,536 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859475341 end=1427859497536 duration=22195 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,541 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 22.196 seconds
2015-03-31 23:38:17,542 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,542 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,542 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:38:17,542 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,544 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,544 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 


drop table average
2015-03-31 23:38:17,545 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:38:17,545 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859497544 end=1427859497545 duration=1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,545 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,546 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=average
2015-03-31 23:38:17,547 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=average	
2015-03-31 23:38:17,549 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:38:17,549 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859497545 end=1427859497549 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,549 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:null, properties:null)
2015-03-31 23:38:17,550 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859497542 end=1427859497550 duration=8 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,550 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,550 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 


drop table average
2015-03-31 23:38:17,550 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859497542 end=1427859497550 duration=8 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,551 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,551 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,551 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:DDL] in serial mode
2015-03-31 23:38:17,552 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=average
2015-03-31 23:38:17,552 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=average	
2015-03-31 23:38:17,554 ERROR [main]: metadata.Hive (Hive.java:getTable(1063)) - Table average not found: default.average table not found
2015-03-31 23:38:17,555 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=average
2015-03-31 23:38:17,555 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=average	
2015-03-31 23:38:17,557 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859497551 end=1427859497557 duration=6 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,558 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859497550 end=1427859497558 duration=8 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,558 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:38:17,558 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,559 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859497558 end=1427859497558 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,559 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859497542 end=1427859497559 duration=17 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,559 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 0.018 seconds
2015-03-31 23:38:17,560 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,560 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,560 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:38:17,560 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,561 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,562 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 
create table average as
select stock_name, stddev_samp(difference) as mean from XiVals group by stock_name
2015-03-31 23:38:17,564 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:38:17,565 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859497561 end=1427859497565 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,565 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,565 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:38:17,566 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeCreateTable(10828)) - Creating table default.average position=13
2015-03-31 23:38:17,566 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:38:17,567 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:38:17,570 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=average
2015-03-31 23:38:17,570 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=average	
2015-03-31 23:38:17,572 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10000)) - Completed phase 1 of Semantic Analysis
2015-03-31 23:38:17,572 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1554)) - Get metadata for source tables
2015-03-31 23:38:17,573 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=XiVals
2015-03-31 23:38:17,573 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=XiVals	
2015-03-31 23:38:17,598 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1702)) - Get metadata for subqueries
2015-03-31 23:38:17,598 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1726)) - Get metadata for destination tables
2015-03-31 23:38:17,598 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:38:17,599 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:38:17,605 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10003)) - Completed getting MetaData in Semantic Analysis
2015-03-31 23:38:17,612 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:genFileSinkPlan(6412)) - Set stats collection dir : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-17_561_219745252521306475-1/-ext-10002
2015-03-31 23:38:17,616 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for FS(6)
2015-03-31 23:38:17,617 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(5)
2015-03-31 23:38:17,617 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for GBY(4)
2015-03-31 23:38:17,617 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for RS(3)
2015-03-31 23:38:17,618 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for GBY(2)
2015-03-31 23:38:17,618 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(1)
2015-03-31 23:38:17,618 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(0)
2015-03-31 23:38:17,621 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(761)) - RS 3 oldColExprMap: {KEY._col0=Column[_col0], VALUE._col0=Column[_col1]}
2015-03-31 23:38:17,621 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(812)) - RS 3 newColExprMap: {KEY._col0=Column[_col0], VALUE._col0=Column[_col1]}
2015-03-31 23:38:17,623 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:38:17,624 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:38:17,626 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_database: default
2015-03-31 23:38:17,627 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_database: default	
2015-03-31 23:38:17,630 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:38:17,631 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427859497630 end=1427859497631 duration=1 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:38:17,633 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:38:17,633 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:38:17,634 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:38:17,634 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:38:17,635 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:38:17,635 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:38:17,636 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10173)) - Completed plan generation
2015-03-31 23:38:17,637 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:38:17,637 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859497565 end=1427859497637 duration=72 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,637 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:mean, type:double, comment:null)], properties:null)
2015-03-31 23:38:17,638 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859497560 end=1427859497638 duration=78 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,638 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,638 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 
create table average as
select stock_name, stddev_samp(difference) as mean from XiVals group by stock_name
2015-03-31 23:38:17,639 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Query ID = u2_20150331233838_4f49cb13-636f-4d60-b673-eab7ae6bf45e
2015-03-31 23:38:17,639 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total jobs = 1
2015-03-31 23:38:17,639 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859497560 end=1427859497639 duration=79 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,640 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,640 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPRED.Stage-1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:17,640 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Launching Job 1 out of 1
2015-03-31 23:38:17,642 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-1:MAPRED] in serial mode
2015-03-31 23:38:17,642 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getInputSummary from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:38:17,644 INFO  [main]: exec.Utilities (Utilities.java:getInputSummary(2562)) - Cache Content Summary for hdfs://k05n22:54310/user/hive/warehouse/xivals length: 0 file count: 1 directory count: 1
2015-03-31 23:38:17,645 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getInputSummary start=1427859497642 end=1427859497645 duration=3 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:38:17,645 INFO  [main]: exec.Utilities (Utilities.java:estimateNumberOfReducers(3119)) - BytesPerReducer=256000000 maxReducers=1009 totalInputFileSize=0
2015-03-31 23:38:17,645 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Number of reduce tasks not specified. Estimated from input data size: 1
2015-03-31 23:38:17,646 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to change the average load for a reducer (in bytes):
2015-03-31 23:38:17,646 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set hive.exec.reducers.bytes.per.reducer=<number>
2015-03-31 23:38:17,646 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to limit the maximum number of reducers:
2015-03-31 23:38:17,647 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set hive.exec.reducers.max=<number>
2015-03-31 23:38:17,647 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to set a constant number of reducers:
2015-03-31 23:38:17,647 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set mapreduce.job.reduces=<number>
2015-03-31 23:38:17,648 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-17_561_219745252521306475-1
2015-03-31 23:38:17,650 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(287)) - Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2015-03-31 23:38:17,651 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3265)) - Processing alias xivals
2015-03-31 23:38:17,651 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3282)) - Adding input file hdfs://k05n22:54310/user/hive/warehouse/xivals
2015-03-31 23:38:17,651 INFO  [main]: exec.Utilities (Utilities.java:isEmptyPath(2601)) - Content Summary hdfs://k05n22:54310/user/hive/warehouse/xivalslength: 0 num files: 1 num directories: 1
2015-03-31 23:38:17,652 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-17_561_219745252521306475-1
2015-03-31 23:38:17,657 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:38:17,657 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapWork via kryo
2015-03-31 23:38:17,671 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859497657 end=1427859497671 duration=14 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:38:17,675 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:38:17,676 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing ReduceWork via kryo
2015-03-31 23:38:17,692 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859497675 end=1427859497692 duration=17 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:38:17,728 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:38:17,732 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-17_561_219745252521306475-1/-ext-10002
2015-03-31 23:38:17,767 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:38:17,780 WARN  [main]: mapreduce.JobSubmitter (JobSubmitter.java:copyAndConfigureFiles(150)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-03-31 23:38:17,946 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:38:17,950 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(387)) - CombineHiveInputSplit creating pool for hdfs://k05n22:54310/user/hive/warehouse/xivals; using filter path hdfs://k05n22:54310/user/hive/warehouse/xivals
2015-03-31 23:38:17,955 INFO  [main]: input.FileInputFormat (FileInputFormat.java:listStatus(281)) - Total input paths to process : 1
2015-03-31 23:38:17,955 INFO  [main]: input.CombineFileInputFormat (CombineFileInputFormat.java:createSplits(413)) - DEBUG: Terminated node allocation with : CompletedNodes: 0, size left: 0
2015-03-31 23:38:17,957 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(442)) - number of splits 1
2015-03-31 23:38:17,958 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getSplits start=1427859497946 end=1427859497958 duration=12 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:38:17,958 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(521)) - Number of all splits 1
2015-03-31 23:38:17,984 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(396)) - number of splits:1
2015-03-31 23:38:18,011 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:printTokens(479)) - Submitting tokens for job: job_1427859192785_0007
2015-03-31 23:38:18,032 INFO  [main]: impl.YarnClientImpl (YarnClientImpl.java:submitApplication(236)) - Submitted application application_1427859192785_0007
2015-03-31 23:38:18,037 INFO  [main]: mapreduce.Job (Job.java:submit(1289)) - The url to track the job: http://k05n22:8088/proxy/application_1427859192785_0007/
2015-03-31 23:38:18,038 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Starting Job = job_1427859192785_0007, Tracking URL = http://k05n22:8088/proxy/application_1427859192785_0007/
2015-03-31 23:38:18,038 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Kill Command = /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop job  -kill job_1427859192785_0007
2015-03-31 23:38:30,321 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2015-03-31 23:38:30,365 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2015-03-31 23:38:30,366 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:38:30,365 Stage-1 map = 0%,  reduce = 0%
2015-03-31 23:38:36,625 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:38:36,625 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.57 sec
2015-03-31 23:38:43,958 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:38:43,957 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.76 sec
2015-03-31 23:38:45,015 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - MapReduce Total cumulative CPU time: 4 seconds 760 msec
2015-03-31 23:38:45,051 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Ended Job = job_1427859192785_0007
2015-03-31 23:38:45,063 INFO  [main]: exec.FileSinkOperator (Utilities.java:mvFileToFinalPath(1805)) - Moving tmp dir: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-17_561_219745252521306475-1/_tmp.-ext-10001 to: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-17_561_219745252521306475-1/-ext-10001
2015-03-31 23:38:45,067 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MOVE.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,067 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-0:MOVE] in serial mode
2015-03-31 23:38:45,068 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Moving data to: hdfs://k05n22:54310/user/hive/warehouse/average from hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-17_561_219745252521306475-1/-ext-10001
2015-03-31 23:38:45,071 INFO  [main]: metadata.Hive (Hive.java:renameFile(2359)) - Replacing src:hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-17_561_219745252521306475-1/-ext-10001;dest: hdfs://k05n22:54310/user/hive/warehouse/average;Status:true
2015-03-31 23:38:45,072 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.DDL.Stage-3 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,072 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-3:DDL] in serial mode
2015-03-31 23:38:45,075 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: create_table: Table(tableName:average, dbName:default, owner:u2, createTime:1427859525, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:mean, type:double, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)
2015-03-31 23:38:45,075 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=create_table: Table(tableName:average, dbName:default, owner:u2, createTime:1427859525, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:stock_name, type:string, comment:null), FieldSchema(name:mean, type:double, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
2015-03-31 23:38:45,086 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for average
2015-03-31 23:38:45,086 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table average to 0
2015-03-31 23:38:45,111 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.STATS.Stage-2 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,111 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-2:STATS] in serial mode
2015-03-31 23:38:45,112 INFO  [main]: exec.StatsTask (StatsTask.java:execute(86)) - Executing stats task
2015-03-31 23:38:45,112 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=average
2015-03-31 23:38:45,113 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=average	
2015-03-31 23:38:45,138 INFO  [main]: fs.FSStatsPublisher (FSStatsPublisher.java:init(49)) - created : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-17_561_219745252521306475-1/-ext-10002
2015-03-31 23:38:45,145 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:connect(68)) - Read stats : {default.average/={}}
2015-03-31 23:38:45,145 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.average/	numRows	0
2015-03-31 23:38:45,145 INFO  [main]: fs.FSStatsAggregator (FSStatsAggregator.java:aggregateStats(95)) - Read stats for : default.average/	rawDataSize	0
2015-03-31 23:38:45,149 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: alter_table: db=default tbl=average newtbl=average
2015-03-31 23:38:45,149 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=alter_table: db=default tbl=average newtbl=average	
2015-03-31 23:38:45,199 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(199)) - Updating table stats fast for average
2015-03-31 23:38:45,199 INFO  [main]: hive.log (MetaStoreUtils.java:updateUnpartitionedTableStatsFast(201)) - Updated size of table average to 0
2015-03-31 23:38:45,220 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Table default.average stats: [numFiles=1, numRows=0, totalSize=0, rawDataSize=0]
2015-03-31 23:38:45,223 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859497640 end=1427859525223 duration=27583 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,224 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859497638 end=1427859525224 duration=27586 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,224 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - MapReduce Jobs Launched: 
2015-03-31 23:38:45,224 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.76 sec   HDFS Read: 209 HDFS Write: 41 SUCCESS
2015-03-31 23:38:45,225 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total MapReduce CPU Time Spent: 4 seconds 760 msec
2015-03-31 23:38:45,225 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:38:45,225 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,226 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859525225 end=1427859525225 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,226 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859497560 end=1427859525226 duration=27666 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,228 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 27.666 seconds
2015-03-31 23:38:45,228 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,228 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,229 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:38:45,229 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,230 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,230 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 

SELECT * FROM average
where mean>0 and mean is not null
ORDER BY mean DESC LIMIT 10
2015-03-31 23:38:45,239 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:38:45,239 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859525230 end=1427859525239 duration=9 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,240 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,240 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:38:45,241 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10000)) - Completed phase 1 of Semantic Analysis
2015-03-31 23:38:45,241 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1554)) - Get metadata for source tables
2015-03-31 23:38:45,241 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=average
2015-03-31 23:38:45,242 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=average	
2015-03-31 23:38:45,266 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1702)) - Get metadata for subqueries
2015-03-31 23:38:45,266 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1726)) - Get metadata for destination tables
2015-03-31 23:38:45,273 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-45_230_2023076753479162489-1
2015-03-31 23:38:45,273 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10003)) - Completed getting MetaData in Semantic Analysis
2015-03-31 23:38:45,345 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:genFileSinkPlan(6412)) - Set stats collection dir : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-45_230_2023076753479162489-1/-ext-10002
2015-03-31 23:38:45,349 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for FS(6)
2015-03-31 23:38:45,349 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(135)) - Processing for LIM(5)
2015-03-31 23:38:45,349 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(4)
2015-03-31 23:38:45,350 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for RS(3)
2015-03-31 23:38:45,350 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(2)
2015-03-31 23:38:45,350 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(410)) - Processing for FIL(1)
2015-03-31 23:38:45,351 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of FIL For Alias : average
2015-03-31 23:38:45,351 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	(mean > 0.0)
2015-03-31 23:38:45,352 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(0)
2015-03-31 23:38:45,352 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of TS For Alias : average
2015-03-31 23:38:45,353 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	(mean > 0.0)
2015-03-31 23:38:45,355 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:38:45,355 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427859525355 end=1427859525355 duration=0 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:38:45,356 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(761)) - RS 3 oldColExprMap: {VALUE._col0=Column[_col0], KEY.reducesinkkey0=Column[_col1]}
2015-03-31 23:38:45,357 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(812)) - RS 3 newColExprMap: {VALUE._col0=Column[_col0], KEY.reducesinkkey0=Column[_col1]}
2015-03-31 23:38:45,364 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:38:45,364 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:38:45,365 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:38:45,365 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:38:45,365 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:38:45,366 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:38:45,367 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10173)) - Completed plan generation
2015-03-31 23:38:45,367 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:38:45,367 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859525240 end=1427859525367 duration=127 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,378 INFO  [main]: exec.ListSinkOperator (Operator.java:initialize(346)) - Initializing Self OP[8]
2015-03-31 23:38:45,381 INFO  [main]: exec.ListSinkOperator (Operator.java:initializeChildren(419)) - Operator 8 OP initialized
2015-03-31 23:38:45,382 INFO  [main]: exec.ListSinkOperator (Operator.java:initialize(394)) - Initialization Done 8 OP
2015-03-31 23:38:45,382 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:average.stock_name, type:string, comment:null), FieldSchema(name:average.mean, type:double, comment:null)], properties:null)
2015-03-31 23:38:45,382 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859525229 end=1427859525382 duration=153 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,382 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,383 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 

SELECT * FROM average
where mean>0 and mean is not null
ORDER BY mean DESC LIMIT 10
2015-03-31 23:38:45,383 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Query ID = u2_20150331233838_b9db6391-356c-4b2b-9dc2-2977e004fd70
2015-03-31 23:38:45,383 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total jobs = 1
2015-03-31 23:38:45,384 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859525228 end=1427859525384 duration=156 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,384 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,384 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPRED.Stage-1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:38:45,385 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Launching Job 1 out of 1
2015-03-31 23:38:45,386 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-1:MAPRED] in serial mode
2015-03-31 23:38:45,387 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Number of reduce tasks determined at compile time: 1
2015-03-31 23:38:45,387 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to change the average load for a reducer (in bytes):
2015-03-31 23:38:45,387 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set hive.exec.reducers.bytes.per.reducer=<number>
2015-03-31 23:38:45,388 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to limit the maximum number of reducers:
2015-03-31 23:38:45,388 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set hive.exec.reducers.max=<number>
2015-03-31 23:38:45,388 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to set a constant number of reducers:
2015-03-31 23:38:45,388 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set mapreduce.job.reduces=<number>
2015-03-31 23:38:45,389 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-45_230_2023076753479162489-1
2015-03-31 23:38:45,391 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(287)) - Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2015-03-31 23:38:45,392 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3265)) - Processing alias average
2015-03-31 23:38:45,392 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3282)) - Adding input file hdfs://k05n22:54310/user/hive/warehouse/average
2015-03-31 23:38:45,392 INFO  [main]: exec.Utilities (Utilities.java:isEmptyPath(2605)) - Content Summary not cached for hdfs://k05n22:54310/user/hive/warehouse/average
2015-03-31 23:38:45,395 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-45_230_2023076753479162489-1
2015-03-31 23:38:45,401 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:38:45,401 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapWork via kryo
2015-03-31 23:38:45,415 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859525401 end=1427859525415 duration=14 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:38:45,419 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:38:45,419 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing ReduceWork via kryo
2015-03-31 23:38:45,433 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859525419 end=1427859525433 duration=14 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:38:45,469 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:38:45,508 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:38:45,523 WARN  [main]: mapreduce.JobSubmitter (JobSubmitter.java:copyAndConfigureFiles(150)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-03-31 23:38:45,690 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:38:45,696 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(387)) - CombineHiveInputSplit creating pool for hdfs://k05n22:54310/user/hive/warehouse/average; using filter path hdfs://k05n22:54310/user/hive/warehouse/average
2015-03-31 23:38:45,700 INFO  [main]: input.FileInputFormat (FileInputFormat.java:listStatus(281)) - Total input paths to process : 1
2015-03-31 23:38:45,701 INFO  [main]: input.CombineFileInputFormat (CombineFileInputFormat.java:createSplits(413)) - DEBUG: Terminated node allocation with : CompletedNodes: 0, size left: 0
2015-03-31 23:38:45,703 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(442)) - number of splits 1
2015-03-31 23:38:45,703 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getSplits start=1427859525690 end=1427859525703 duration=13 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:38:45,704 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(521)) - Number of all splits 1
2015-03-31 23:38:45,726 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(396)) - number of splits:1
2015-03-31 23:38:45,758 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:printTokens(479)) - Submitting tokens for job: job_1427859192785_0008
2015-03-31 23:38:45,780 INFO  [main]: impl.YarnClientImpl (YarnClientImpl.java:submitApplication(236)) - Submitted application application_1427859192785_0008
2015-03-31 23:38:45,784 INFO  [main]: mapreduce.Job (Job.java:submit(1289)) - The url to track the job: http://k05n22:8088/proxy/application_1427859192785_0008/
2015-03-31 23:38:45,785 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Starting Job = job_1427859192785_0008, Tracking URL = http://k05n22:8088/proxy/application_1427859192785_0008/
2015-03-31 23:38:45,785 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Kill Command = /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop job  -kill job_1427859192785_0008
2015-03-31 23:38:57,075 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2015-03-31 23:38:57,122 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2015-03-31 23:38:57,122 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:38:57,121 Stage-1 map = 0%,  reduce = 0%
2015-03-31 23:39:04,498 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:39:04,498 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.93 sec
2015-03-31 23:39:12,917 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:39:12,917 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.89 sec
2015-03-31 23:39:13,975 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - MapReduce Total cumulative CPU time: 4 seconds 890 msec
2015-03-31 23:39:14,010 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Ended Job = job_1427859192785_0008
2015-03-31 23:39:14,024 INFO  [main]: exec.FileSinkOperator (Utilities.java:mvFileToFinalPath(1805)) - Moving tmp dir: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-45_230_2023076753479162489-1/_tmp.-ext-10001 to: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-38-45_230_2023076753479162489-1/-ext-10001
2015-03-31 23:39:14,029 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859525384 end=1427859554029 duration=28645 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,029 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859525382 end=1427859554029 duration=28647 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,030 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - MapReduce Jobs Launched: 
2015-03-31 23:39:14,030 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.89 sec   HDFS Read: 210 HDFS Write: 0 SUCCESS
2015-03-31 23:39:14,030 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total MapReduce CPU Time Spent: 4 seconds 890 msec
2015-03-31 23:39:14,031 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:39:14,031 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,031 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859554031 end=1427859554031 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,031 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859525228 end=1427859554031 duration=28803 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,043 INFO  [main]: exec.ListSinkOperator (Operator.java:close(595)) - 8 finished. closing... 
2015-03-31 23:39:14,044 INFO  [main]: exec.ListSinkOperator (Operator.java:close(613)) - 8 Close done
2015-03-31 23:39:14,047 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 28.804 seconds
2015-03-31 23:39:14,047 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,048 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,048 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:39:14,048 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,050 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,051 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: 



SELECT * FROM average
where mean>0 and mean is not null
ORDER BY mean ASC LIMIT 10
2015-03-31 23:39:14,053 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(206)) - Parse Completed
2015-03-31 23:39:14,054 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=parse start=1427859554050 end=1427859554054 duration=4 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,054 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,054 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(9961)) - Starting Semantic Analysis
2015-03-31 23:39:14,055 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10000)) - Completed phase 1 of Semantic Analysis
2015-03-31 23:39:14,055 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1554)) - Get metadata for source tables
2015-03-31 23:39:14,055 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:logInfo(713)) - 0: get_table : db=default tbl=average
2015-03-31 23:39:14,056 INFO  [main]: HiveMetaStore.audit (HiveMetaStore.java:logAuditEvent(339)) - ugi=u2	ip=unknown-ip-addr	cmd=get_table : db=default tbl=average	
2015-03-31 23:39:14,081 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1702)) - Get metadata for subqueries
2015-03-31 23:39:14,082 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:getMetaData(1726)) - Get metadata for destination tables
2015-03-31 23:39:14,085 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-39-14_050_176343919455585850-1
2015-03-31 23:39:14,085 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10003)) - Completed getting MetaData in Semantic Analysis
2015-03-31 23:39:14,090 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:genFileSinkPlan(6412)) - Set stats collection dir : hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-39-14_050_176343919455585850-1/-ext-10002
2015-03-31 23:39:14,093 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for FS(6)
2015-03-31 23:39:14,093 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(135)) - Processing for LIM(5)
2015-03-31 23:39:14,094 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(4)
2015-03-31 23:39:14,094 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for RS(3)
2015-03-31 23:39:14,094 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(771)) - Processing for SEL(2)
2015-03-31 23:39:14,095 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(410)) - Processing for FIL(1)
2015-03-31 23:39:14,095 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of FIL For Alias : average
2015-03-31 23:39:14,096 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	(mean > 0.0)
2015-03-31 23:39:14,096 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:process(390)) - Processing for TS(0)
2015-03-31 23:39:14,097 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(823)) - Pushdown Predicates of TS For Alias : average
2015-03-31 23:39:14,097 INFO  [main]: ppd.OpProcFactory (OpProcFactory.java:logExpr(826)) - 	(mean > 0.0)
2015-03-31 23:39:14,099 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:39:14,099 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=partition-retrieving start=1427859554099 end=1427859554099 duration=0 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
2015-03-31 23:39:14,100 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(761)) - RS 3 oldColExprMap: {VALUE._col0=Column[_col0], KEY.reducesinkkey0=Column[_col1]}
2015-03-31 23:39:14,101 INFO  [main]: optimizer.ColumnPrunerProcFactory (ColumnPrunerProcFactory.java:pruneReduceSinkOperator(812)) - RS 3 newColExprMap: {VALUE._col0=Column[_col0], KEY.reducesinkkey0=Column[_col1]}
2015-03-31 23:39:14,104 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:39:14,104 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:39:14,105 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:39:14,105 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:39:14,105 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(154)) - Looking for table scans where optimization is applicable
2015-03-31 23:39:14,106 INFO  [main]: physical.NullScanTaskDispatcher (NullScanTaskDispatcher.java:dispatch(178)) - Found 0 null table scans
2015-03-31 23:39:14,107 INFO  [main]: parse.SemanticAnalyzer (SemanticAnalyzer.java:analyzeInternal(10173)) - Completed plan generation
2015-03-31 23:39:14,107 INFO  [main]: ql.Driver (Driver.java:compile(427)) - Semantic Analysis Completed
2015-03-31 23:39:14,107 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=semanticAnalyze start=1427859554054 end=1427859554107 duration=53 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,108 INFO  [main]: exec.ListSinkOperator (Operator.java:initialize(346)) - Initializing Self OP[8]
2015-03-31 23:39:14,109 INFO  [main]: exec.ListSinkOperator (Operator.java:initializeChildren(419)) - Operator 8 OP initialized
2015-03-31 23:39:14,109 INFO  [main]: exec.ListSinkOperator (Operator.java:initialize(394)) - Initialization Done 8 OP
2015-03-31 23:39:14,109 INFO  [main]: ql.Driver (Driver.java:getSchema(235)) - Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:average.stock_name, type:string, comment:null), FieldSchema(name:average.mean, type:double, comment:null)], properties:null)
2015-03-31 23:39:14,109 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859554048 end=1427859554109 duration=61 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,110 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,110 INFO  [main]: ql.Driver (Driver.java:execute(1285)) - Starting command: 



SELECT * FROM average
where mean>0 and mean is not null
ORDER BY mean ASC LIMIT 10
2015-03-31 23:39:14,110 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Query ID = u2_20150331233939_82dd5d05-0818-4c3a-bdfe-74f8c72efd18
2015-03-31 23:39:14,111 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total jobs = 1
2015-03-31 23:39:14,111 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=TimeToSubmit start=1427859554048 end=1427859554111 duration=63 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,111 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,111 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=task.MAPRED.Stage-1 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:14,112 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Launching Job 1 out of 1
2015-03-31 23:39:14,113 INFO  [main]: ql.Driver (Driver.java:launchTask(1602)) - Starting task [Stage-1:MAPRED] in serial mode
2015-03-31 23:39:14,114 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Number of reduce tasks determined at compile time: 1
2015-03-31 23:39:14,114 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to change the average load for a reducer (in bytes):
2015-03-31 23:39:14,114 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set hive.exec.reducers.bytes.per.reducer=<number>
2015-03-31 23:39:14,115 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to limit the maximum number of reducers:
2015-03-31 23:39:14,115 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set hive.exec.reducers.max=<number>
2015-03-31 23:39:14,115 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - In order to set a constant number of reducers:
2015-03-31 23:39:14,116 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) -   set mapreduce.job.reduces=<number>
2015-03-31 23:39:14,116 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-39-14_050_176343919455585850-1
2015-03-31 23:39:14,118 INFO  [main]: mr.ExecDriver (ExecDriver.java:execute(287)) - Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
2015-03-31 23:39:14,119 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3265)) - Processing alias average
2015-03-31 23:39:14,119 INFO  [main]: exec.Utilities (Utilities.java:getInputPaths(3282)) - Adding input file hdfs://k05n22:54310/user/hive/warehouse/average
2015-03-31 23:39:14,119 INFO  [main]: exec.Utilities (Utilities.java:isEmptyPath(2605)) - Content Summary not cached for hdfs://k05n22:54310/user/hive/warehouse/average
2015-03-31 23:39:14,122 INFO  [main]: ql.Context (Context.java:getMRScratchDir(266)) - New scratch dir is hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-39-14_050_176343919455585850-1
2015-03-31 23:39:14,127 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:39:14,128 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing MapWork via kryo
2015-03-31 23:39:14,143 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859554127 end=1427859554143 duration=16 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:39:14,147 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:39:14,148 INFO  [main]: exec.Utilities (Utilities.java:serializePlan(899)) - Serializing ReduceWork via kryo
2015-03-31 23:39:14,163 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=serializePlan start=1427859554147 end=1427859554163 duration=16 from=org.apache.hadoop.hive.ql.exec.Utilities>
2015-03-31 23:39:14,197 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:39:14,234 INFO  [main]: client.RMProxy (RMProxy.java:createRMProxy(92)) - Connecting to ResourceManager at k05n22/10.111.5.22:8032
2015-03-31 23:39:14,252 WARN  [main]: mapreduce.JobSubmitter (JobSubmitter.java:copyAndConfigureFiles(150)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-03-31 23:39:14,424 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:39:14,428 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(387)) - CombineHiveInputSplit creating pool for hdfs://k05n22:54310/user/hive/warehouse/average; using filter path hdfs://k05n22:54310/user/hive/warehouse/average
2015-03-31 23:39:14,432 INFO  [main]: input.FileInputFormat (FileInputFormat.java:listStatus(281)) - Total input paths to process : 1
2015-03-31 23:39:14,433 INFO  [main]: input.CombineFileInputFormat (CombineFileInputFormat.java:createSplits(413)) - DEBUG: Terminated node allocation with : CompletedNodes: 0, size left: 0
2015-03-31 23:39:14,435 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getCombineSplits(442)) - number of splits 1
2015-03-31 23:39:14,435 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=getSplits start=1427859554424 end=1427859554435 duration=11 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
2015-03-31 23:39:14,436 INFO  [main]: io.CombineHiveInputFormat (CombineHiveInputFormat.java:getSplits(521)) - Number of all splits 1
2015-03-31 23:39:14,463 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(396)) - number of splits:1
2015-03-31 23:39:14,491 INFO  [main]: mapreduce.JobSubmitter (JobSubmitter.java:printTokens(479)) - Submitting tokens for job: job_1427859192785_0009
2015-03-31 23:39:14,512 INFO  [main]: impl.YarnClientImpl (YarnClientImpl.java:submitApplication(236)) - Submitted application application_1427859192785_0009
2015-03-31 23:39:14,517 INFO  [main]: mapreduce.Job (Job.java:submit(1289)) - The url to track the job: http://k05n22:8088/proxy/application_1427859192785_0009/
2015-03-31 23:39:14,518 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Starting Job = job_1427859192785_0009, Tracking URL = http://k05n22:8088/proxy/application_1427859192785_0009/
2015-03-31 23:39:14,518 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Kill Command = /util/academic/hadoop/2.5.1/hadoop-2.5.1/bin/hadoop job  -kill job_1427859192785_0009
2015-03-31 23:39:26,919 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2015-03-31 23:39:26,955 WARN  [main]: mapreduce.Counters (AbstractCounters.java:getGroup(234)) - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2015-03-31 23:39:26,955 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:39:26,955 Stage-1 map = 0%,  reduce = 0%
2015-03-31 23:39:34,296 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:39:34,294 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.11 sec
2015-03-31 23:39:41,611 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - 2015-03-31 23:39:41,611 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.54 sec
2015-03-31 23:39:42,667 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - MapReduce Total cumulative CPU time: 4 seconds 540 msec
2015-03-31 23:39:42,701 INFO  [main]: exec.Task (SessionState.java:printInfo(824)) - Ended Job = job_1427859192785_0009
2015-03-31 23:39:42,714 INFO  [main]: exec.FileSinkOperator (Utilities.java:mvFileToFinalPath(1805)) - Moving tmp dir: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-39-14_050_176343919455585850-1/_tmp.-ext-10001 to: hdfs://k05n22:54310/tmp/hive/u2/909943e7-06d0-467b-836c-1fae91405551/hive_2015-03-31_23-39-14_050_176343919455585850-1/-ext-10001
2015-03-31 23:39:42,719 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=runTasks start=1427859554111 end=1427859582719 duration=28608 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:42,719 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.execute start=1427859554110 end=1427859582719 duration=28609 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:42,720 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - MapReduce Jobs Launched: 
2015-03-31 23:39:42,720 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.54 sec   HDFS Read: 210 HDFS Write: 0 SUCCESS
2015-03-31 23:39:42,720 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - Total MapReduce CPU Time Spent: 4 seconds 540 msec
2015-03-31 23:39:42,721 INFO  [main]: ql.Driver (SessionState.java:printInfo(824)) - OK
2015-03-31 23:39:42,721 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:42,721 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859582721 end=1427859582721 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:42,721 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=Driver.run start=1427859554047 end=1427859582721 duration=28674 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:42,725 INFO  [main]: exec.ListSinkOperator (Operator.java:close(595)) - 8 finished. closing... 
2015-03-31 23:39:42,726 INFO  [main]: exec.ListSinkOperator (Operator.java:close(613)) - 8 Close done
2015-03-31 23:39:42,729 INFO  [main]: CliDriver (SessionState.java:printInfo(824)) - Time taken: 28.675 seconds
2015-03-31 23:39:42,729 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:42,729 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859582729 end=1427859582729 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:45,273 WARN  [main]: common.LogUtils (LogUtils.java:logConfigLocation(140)) - DEPRECATED: Ignoring hive-default.xml found on the CLASSPATH at /gpfs/courses/cse587/spring2015/students/u2/hw3/hive_official/src/config-3611420/hive-default.xml
2015-03-31 23:39:45,275 WARN  [main]: common.LogUtils (LogUtils.java:logConfigLocation(145)) - hive-site.xml not found on CLASSPATH
2015-03-31 23:39:45,421 INFO  [main]: SessionState (SessionState.java:printInfo(824)) - 
Logging initialized using configuration in file:/gpfs/courses/cse587/spring2015/students/u2/hw3/hive_official/src/config-3611420/hive-log4j.properties
2015-03-31 23:39:45,618 WARN  [main]: util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(62)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-03-31 23:39:45,674 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:newRawStore(556)) - 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
2015-03-31 23:39:45,698 INFO  [main]: metastore.ObjectStore (ObjectStore.java:initialize(264)) - ObjectStore, initialize called
2015-03-31 23:39:52,595 INFO  [main]: metastore.ObjectStore (ObjectStore.java:getPMF(345)) - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2015-03-31 23:39:52,687 INFO  [main]: metastore.MetaStoreDirectSql (MetaStoreDirectSql.java:<init>(109)) - MySQL check failed, assuming we are not on mysql: Lexical error at line 1, column 5.  Encountered: "@" (64), after : "".
2015-03-31 23:39:54,868 INFO  [main]: metastore.ObjectStore (ObjectStore.java:setConf(247)) - Initialized ObjectStore
2015-03-31 23:39:55,196 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:createDefaultRoles_core(630)) - Added admin role in metastore
2015-03-31 23:39:55,199 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:createDefaultRoles_core(639)) - Added public role in metastore
2015-03-31 23:39:55,343 INFO  [main]: metastore.HiveMetaStore (HiveMetaStore.java:addAdminUsers_core(679)) - No user is added in admin role, since config is empty
2015-03-31 23:39:56,094 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created local directory: /tmp/e5246d52-500f-4855-a395-61f00d8c7c0e_resources
2015-03-31 23:39:56,108 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created HDFS directory: /tmp/hive/u2/e5246d52-500f-4855-a395-61f00d8c7c0e
2015-03-31 23:39:56,123 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created local directory: /tmp/u2/e5246d52-500f-4855-a395-61f00d8c7c0e
2015-03-31 23:39:56,127 INFO  [main]: session.SessionState (SessionState.java:createPath(558)) - Created HDFS directory: /tmp/hive/u2/e5246d52-500f-4855-a395-61f00d8c7c0e/_tmp_space.db
2015-03-31 23:39:56,131 INFO  [main]: session.SessionState (SessionState.java:start(460)) - No Tez session required at this point. hive.execution.engine=mr.
2015-03-31 23:39:56,166 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:56,166 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:56,166 INFO  [main]: ql.Driver (Driver.java:checkConcurrency(155)) - Concurrency mode is disabled, not creating a lock manager
2015-03-31 23:39:56,167 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:56,235 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:56,243 INFO  [main]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: SELECT * FROM average where mean>0 and mean is not null ORDER BY mean DESC LIMIT 10 UNION SELECT * FROM average where mean>0 and mean is not null ORDER BY mean ASC LIMIT 10
2015-03-31 23:39:56,709 ERROR [main]: ql.Driver (SessionState.java:printError(833)) - FAILED: ParseException line 1:90 missing ALL at 'SELECT' near '<EOF>'
org.apache.hadoop.hive.ql.parse.ParseException: line 1:90 missing ALL at 'SELECT' near '<EOF>'
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:210)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:389)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:303)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1067)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1129)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1004)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:994)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:247)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:199)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:410)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:345)
	at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:733)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:677)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:616)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:212)

2015-03-31 23:39:56,709 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=compile start=1427859596167 end=1427859596709 duration=542 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:56,710 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:56,710 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859596710 end=1427859596710 duration=0 from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:56,714 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogBegin(108)) - <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
2015-03-31 23:39:56,714 INFO  [main]: log.PerfLogger (PerfLogger.java:PerfLogEnd(135)) - </PERFLOG method=releaseLocks start=1427859596714 end=1427859596714 duration=0 from=org.apache.hadoop.hive.ql.Driver>
